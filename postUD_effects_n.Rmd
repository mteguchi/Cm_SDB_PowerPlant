---
title: "Compare pre vs. post periods"
output: html_notebook
---

This file contains code to compare pre and post periods by randomly extracting the same number of individuals as the pre period from the post period without replacement and compare the calculated HR areas. It also looks at the northern most latitude of 95% and 50% UDs.

```{r}
rm(list = ls())
ifelse(Sys.info()[1] == 'Linux',
       source('~/Documents/R/tools/TomosFunctions.R'),
       source('~/R/tools/TomosFunctions.R'))

#library(readxl)
library(dplyr)
library(adehabitatHR)
library(rgdal)
library(leaflet) 
library(ggplot2)
library(lubridate)
library(tidyverse)

run.date <- "2018-09-24"
run.date2 <- "2018-09-24"

# internet <- F #TRUE
# save.figure <- T

# Minimum number of relocations per individual to be included in HR analysis
min_n <- 50
#N.end <- 32.69   # approx Coronado bridge
N.end <- 32.66 # changed from 32.69 because 152314 had a gap in data points between ~32.65 and ~32.66 - seems like there was a different behavior south and north of 32.66

source("HR_analysis_fcns.R")
tagprj <- readOGR(dsn = "Tag_065_UTMzone11n", 
                  layer = "tag_065_project")
tagproj <- proj4string(tagprj)

```

Load results from HR_analysis_GPS_LC_newtags_11July2018.Rmd. The following files contain raw data for pre and post periods.

```{r}
post.all <- read.csv("data/Post_GPS_LC_all_2018-09-18.csv")
pre.all <- read.csv("data/Pre_GPS_LC_all_2018-09-18.csv")

pre.kd <- HR.analysis.step1(min_n, pre.all, tagproj, grid = 300)
post.kd <- HR.analysis.step1(min_n, post.all, tagproj, grid = 300)

h.pre.1 <- find.h.adhoc(pre.kd$list.data$all.utm)
## Section 3.1.2
##Visually optimized hlim = c(0.565,1.5), grid=300
# grid values from 50 to 300 don't change the outcome;
# extent values from 1 to 200 don't change the outcome either

h.pre <- round(h.pre.1$h)

pre.HR <- compute.area(h.pre, 
                       pre.kd$list.data, 
                       grid = 300)

```

Select all possible combinations of 6 (ID.pre.min_n) individuals from the post data. Only 1000 combinations are selected per number of individuals.  

```{r echo=FALSE, results="hide"}
post.summary <- read.csv("data/post_sample_summary_2018-09-18.csv")
ID.post.min_n <- filter(post.summary,
                       n.relocations > (min_n - 1))

pre.summary <- read.csv("data/pre_sample_summary_2018-09-18.csv")
ID.pre.min_n <- filter(pre.summary,
                       n.relocations > (min_n - 1))

#h.multiplier <-  seq(from = 0.1, to = 0.95, by = 0.05) 
# This loop takes a long time... It was run once already so start from 
# where it was left off. .RData file needs to be loaded to figure out
# how far along the first attempt was. 
grid <- 1000
extent <- 1

if (!file.exists(paste0("RData/areas_combos_", run.date, ".rds"))){
  combos <- combn(1:dim(ID.post.min_n)[1], 
                  dim(ID.pre.min_n)[1])
  combos <- combos[, sample(1:ncol(combos), 
                            size = 1000)]
  IDs <- ver.95.df.list <- pts.df.list <- vector(mode = "list", 
                                                 length = ncol(combos))
  area.95 <- area.50 <- lat.N <- vector(mode = "numeric", 
                                        length = ncol(combos))
  
  #p.list <- list()
  for (k in 1:ncol(combos)){
    ID.post.tmp <- data.frame(ArgosID = ID.post.min_n[combos[,k], "ArgosID"])
    post.tmp <- left_join(ID.post.tmp, post.all, by = "ArgosID")
    post.tmp.kd <- HR.analysis.step1(min_n, 
                                     post.tmp, 
                                     tagproj, 
                                     grid = grid)

    h.post.tmp <- find.h.adhoc(post.tmp.kd$list.data$all.utm,
                               grid = grid, extent = extent)
    
    h.post <- round(h.post.tmp$h)

    post.HR <- compute.area(h.post, 
                            post.tmp.kd$list.data, 
                            grid = grid)
    
    tmp.HR <- HR.bvnorm.fcn(all.utm = post.tmp.kd$list.data$all.utm,
                            byID.utm = post.tmp.kd$list.data$byID.utm,
                            h = h.pre,
                            hlim=c(0.03, 1.5),
                            grid=grid, extent = extent)
    
    ver.95.df.list <- broom::tidy(spTransform(getverticeshr(tmp.HR$all.kd, 95),
                                              CRS("+proj=longlat")))
    
    pts.df.list <- data.frame(lon = post.tmp.kd$list.data$all.coords@coords[,1],
                              lat = post.tmp.kd$list.data$all.coords@coords[,2])
    
    # p.list[[k]] <- ggplot() +
    #   geom_polygon(data = tmp.df, aes(x = long, y = lat, group = group)) +
    #   geom_point(data = pts.df, aes(x = lon, y = lat),
    #              color = "green") + coord_map()
    
    area.50[k] <- tmp.HR$area.all["50"]
    area.95[k] <- tmp.HR$area.all["95"]
    lat.N[k] <- max(ver.95.df.list$lat)
    
    IDs[[k]] <- ID.post.tmp[,1]
  }
  
  areas.combos <- list(area95 = area.95,
                       area50 = area.50,
                       Nmost.area95 = lat.N,
                       ID = IDs,
                       polygon = ver.95.df.list,
                       points = pts.df.list,
                       combos = combos)
  
  saveRDS(areas.combos,
          file = paste0("RData/areas_combos_", Sys.Date(), ".rds"))
  
} else {
  areas.combos <- readRDS(file = paste0("RData/areas_combos_", 
                                        run.date, ".rds"))
}

```

Compare the randomized areas and the pre area or plot the difference between the pre area and the randomized post areas.
```{r}
dif.50.df <- data.frame(dif = areas.combos$area50 - pre.HR$area.50)
dif.95.df <- data.frame(dif = areas.combos$area95 - pre.HR$area.95)

hist.dif.50 <- ggplot(data = dif.50.df) + 
  geom_histogram(aes(x = dif), binwidth = 0.1) +
  labs(x = "Difference in area", y = "Count")

# find the ecdf of the differences
Fn.50 <- ecdf(dif.50.df$dif)

# compute the probability at 0:
Fn.50.0 <- Fn.50(0)

#plot(hist.dif.50)

hist.dif.95 <- ggplot(data = dif.95.df) + 
  geom_histogram(aes(x = dif), binwidth = 0.15) +
  labs(x = "Difference in area", y = "Count")

# find the ecdf of the differences
Fn.95 <- ecdf(dif.95.df$dif)

# compute the probability at 0:
Fn.95.0 <- Fn.95(0)

#plot(hist.dif.95)

# quantile(dif.50.df$dif, c(0.025, 0.05, 0.10, 0.15, 0.50, 0.975))
#quantile(dif.95.df$dif, c(0.025, 0.05, 0.10, 0.15, 0.50, 0.975))
# 
# dif.50.df %>% count(dif>0)
# 
# dif.95.df %>% count(dif > 0)


```

THE FOLLOWING PARAGRAPH NEEDS TO BE CLARIFIED... CONFUSING...
The 95 percentiles of 95% UDs ranged from ```r signif(quantile(areas.combo$area95, 0.025), 3)``` to ```r signif(quantile(areas.combo$area95, 0.975), 3)``` when using six turtles at a time. The computed 95% UD for the pre dataset was ```r signif(post.HR$area.95, 3)```, which was about ```r signif(Fn.95(signif(post.HR$area.95, 3))) * 100``` percentile of UDs for the post dataset. This indicated the UDs increased from the pre to post periods. 

Another thing I should do is to look at how many individuals would be needed to stabilize the computed UDs. So, using the larger dataset (post), I should randomly draw n individuals, compute UDs, and repeat the process to see how variable the UDs are. Hopefully, we see the line plateaus at about six... 

```{r}
max.n <- dim(ID.post.min_n)[1] - 1
for (k1 in 5:max.n){
  if (k1 != dim(ID.pre.min_n)[1]){   # this has been done already
    if (!file.exists(paste0("RData/areas_combos_n", k1, "_", run.date2, ".rds"))){
      combos <- combn(1:dim(ID.post.min_n)[1], k1)
      if (ncol(combos) > 1000){
        combos <- combos[, sample(1:ncol(combos), size = 1000)]
      }
      IDs <- ver.95.df.list <- pts.df.list <- vector(mode = "list", 
                                                     length = ncol(combos))
      area.95 <- area.50 <- lat.N <- vector(mode = "numeric", 
                                            length = ncol(combos))
      
      #p.list <- list()
      for (k in 1:ncol(combos)){
        ID.post.tmp <- data.frame(ArgosID = ID.post.min_n[combos[,k], "ArgosID"])
        post.tmp <- left_join(ID.post.tmp, post.all, by = "ArgosID")
        post.tmp.kd <- HR.analysis.step1(min_n, 
                                         post.tmp, 
                                         tagproj, 
                                         grid = grid)
        
        h.post.tmp <- find.h.adhoc(post.tmp.kd$list.data$all.utm,
                                   grid = grid, extent = extent)
        
        h.post <- round(h.post.tmp$h)
        
        post.HR <- compute.area(h.post, 
                                post.tmp.kd$list.data, 
                                grid = grid)
        
        tmp.HR <- HR.bvnorm.fcn(all.utm = post.tmp.kd$list.data$all.utm,
                                byID.utm = post.tmp.kd$list.data$byID.utm,
                                h = h.pre,
                                hlim=c(0.03, 1.5),
                                grid=grid, extent = extent)
        
        ver.95.df.list <- broom::tidy(spTransform(getverticeshr(tmp.HR$all.kd, 95),
                                                  CRS("+proj=longlat")))
        
        pts.df.list <- data.frame(lon = post.tmp.kd$list.data$all.coords@coords[,1],
                                  lat = post.tmp.kd$list.data$all.coords@coords[,2])
        
        # p.list[[k]] <- ggplot() +
        #   geom_polygon(data = tmp.df, aes(x = long, y = lat, group = group)) +
        #   geom_point(data = pts.df, aes(x = lon, y = lat),
        #              color = "green") + coord_map()
        
        area.50[k] <- tmp.HR$area.all["50"]
        area.95[k] <- tmp.HR$area.all["95"]
        lat.N[k] <- max(ver.95.df.list$lat)
        
        IDs[[k]] <- ID.post.tmp[,1]
      }
      
      areas.combos <- list(area95 = area.95,
                           area50 = area.50,
                           Nmost.area95 = lat.N,
                           ID = IDs,
                           polygon = ver.95.df.list,
                           points = pts.df.list,
                           combos = combos)
      
      saveRDS(areas.combos,
              file = paste0("RData/areas_combos_n", k1, "_", 
                            Sys.Date(), ".rds"))
    }
    
  }
  
  
} 

```

