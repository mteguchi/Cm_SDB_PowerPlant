---
title: "R Notebook"
output: html_notebook
---

San Diego Bay Turtle Movement Analysis
Original R Code, JT Froeschke, December 29, 2015
Data modified from previous versions by SE Graham, June 2016, May 2018
Data modified from May 2018 by T EGuchi, July 2018

Filtered data utilize GPS, and Argos LC = 1,2,3
Filtered data do not include points on land
Filtered data only allow for 1 relocation every 4 horus

Purpose of the script is to compute homerange (area) using 
least squares cross-validation including 50% and 95% contours.
An analysis of each turtle and an aggregate pre and post will be computed
h values are chosen based on best judgment and gst behavior  

```{r}
rm(list = ls())
#getwd()
#list.files()

#Section 1: Load libraries and set wd
library(readxl)
library(dplyr)
library(adehabitatHR)
library(readxl)
library(rgdal)
library(leaflet) 
library(ggplot2)

internet <- FALSE
# Minimum number of relocations per individual to be included in HR analysis
min_n <- 50

# a function to create a data frame with minimum number of data points per individual
# then convert geographic coordinates so HR can be computed. Creates a list of length
# four. tagproj is the projection definition, which is defined at the end of next chunk

make.HR.dataset <- function(data.all, ID.min_n, tagproj){
  selected <- dplyr::right_join(data.all, 
                                ID.min_n, 
                                by = "ArgosID")
  
  all.coords <- data.frame(x=selected$Lon1, 
                           y=selected$Lat1)
  
  coordinates(all.coords) <- ~ x + y
  proj4string(all.coords) <- CRS(latlong)
  all.utm <- spTransform(all.coords, tagproj)

  byID.coords <- data.frame(x=selected$Lon1, 
                            y=selected$Lat1,
                            ID = as.factor(selected$ArgosID))
  coordinates(byID.coords) <- ~ x + y
  proj4string(byID.coords) <- CRS(latlong)
  byID.utm <- spTransform(byID.coords, tagproj)
  return(list(all.coords = all.coords,
              all.utm = all.utm,
              byID.coords = byID.coords,
              byID.utm = byID.utm))
}

HR.bvnorm.fcn <- function(all.utm, 
                          byID.utm, 
                          h, 
                          hlim=c(0.03, 1.5), 
                          grid=300, extent = 1){
  
  all.kd <- kernelUD(all.utm, 
                     h = h,  
                     hlim = hlim, 
                     grid = grid,
                     extent = extent,
                     kern = "bivnorm")
  
  Area.all <- kernel.area(all.kd, 
                          percent = c(50, 95),
                          unin = c("m"),
                          unout = c("km2"), 
                          standardize = FALSE)

  byID.kd <- kernelUD(byID.utm, 
                      h = all.kd@h$h ,  
                      hlim = hlim, 
                      grid = grid,
                      extent = extent,
                      kern = "bivnorm")
  
  Area.byID <- kernel.area(byID.kd, 
                           percent = c(50, 95),
                           unin = c("m"),
                           unout = c("km2"), 
                           standardize = FALSE)

  bw <- all.kd@h$h ##bandwidth estimate
  #Area.50 <- Area.all["50"]
  #Area.95 <- Area.all["95"]
  
  #ver.50 <- getverticeshr(all.kd, 50)
  #ver.95 <- getverticeshr(all.kd, 95)
  
  return(list(bw = bw,
              all.kd = all.kd,
              byID.kd = byID.kd,
              area.all = Area.all,
              area.byID = Area.byID))
}

```

Get some base layer maps here:

```{r}
# just use the 2014 eelgrass data - there are old data files also
SDBay.eelg.2014 <- spTransform(readOGR(dsn = "GISfiles/Features",
                                       layer = "SD_Baywide_Eelgrass_2014_Final",
                                       verbose = F),
                               CRS("+proj=longlat +datum=WGS84"))
SDBay.eelg.2014.df <- broom::tidy(SDBay.eelg.2014)

SDBay.eelg.2008 <- spTransform(readOGR(dsn = "GISfiles/Features",
                                       layer = "SD_Baywide_Eelgrass_2008",
                                       verbose = F),
                               CRS("+proj=longlat +datum=WGS84"))
SDBay.eelg.2008.df <- broom::tidy(SDBay.eelg.2008)

if (internet){
  sdbay.all <- ggmap::get_map(location = c(lon = -117.15,
                                           lat = 32.65),
                       zoom = 12,
                       maptype = "satellite",
                       color = "bw",
                       filename = 'sdbay_all',
                       force = F)
  saveRDS(sdbay.all, file = 'RData/sdbay_all.rds')

  sdbay.south <- ggmap::get_map(location = c(lon = -117.117,
                                             lat = 32.625),
                         zoom = 14,
                         maptype = "satellite",
                         color = "bw",
                         filename = 'sdbay_south',
                         force = F)
  saveRDS(sdbay.south, file = 'RData/sdbay_south.rds')

  sdbay.med <- ggmap::get_map(location = c(lon =  -117.117,
                                           lat = 32.625),
                       zoom = 13,
                       maptype = "satellite",
                       color = "bw",
                       filename = 'sdbay_med',
                       force = F)
  saveRDS(sdbay.med, file = 'RData/sdbay_med.rds')
} else {
  sdbay.all <- readRDS(file = 'RData/sdbay_all.rds')
  sdbay.south <- readRDS(file = 'RData/sdbay_south.rds')
  sdbay.med <- readRDS(file = 'RData/sdbay_med.rds')
}

map.sdbay.zm <- ggmap::ggmap(sdbay.all)

map.sdbay.south <- ggmap::ggmap(sdbay.south)

map.sdbay.med <- ggmap::ggmap(sdbay.med)

# read in the SDB shape file:
SDB.shape <- readOGR(dsn = "GISFiles", layer = "sd_bay")
SDBay <- spTransform(readOGR(dsn = "GISfiles",
                             layer = "sd_bay",
                             verbose = F),
                     CRS("+proj=longlat +datum=WGS84"))
SDBay.df <- broom::tidy(SDBay)

water <- spTransform(readOGR(dsn = "GISFiles", 
                             layer = "water",
                             verbose = F),
                     CRS("+proj=longlat +datum=WGS84"))
water.df <- broom::tidy(water) %>%
  filter(lat < 32.75 & lat > 32.58 & long > -117.25)

tagprj <- readOGR(dsn = "Tag_065_UTMzone11n", 
                  layer = "tag_065_project")
tagproj <- proj4string(tagprj)

# not sure what this part is doing... 
latlong = "+init=epsg:4326"
```

Section 2: read in data

Section 2.1: Pre

```{r}
ID.names <- function(name){
  x <- unlist(strsplit(name, '_'))[1]
  return(x)
}
dname <- "data/files_Apr2018_withNewTags/pre/"
pre.files <- dir(path = dname, 
                 pattern = "_inside_DayNight_4hrs_2018-07-11.csv")

pre.IDs <- unlist(lapply(pre.files, FUN = ID.names))

pre.all <- do.call(rbind, 
                   lapply(pre.files,
                          FUN = function(x) read.csv(paste0(dname, x)))) %>%
  mutate(ID.f = as.factor(ArgosID)) %>%
  filter(include == 1)


write.csv(pre.all, paste0(dname, "Pre_GPS_LC_all.csv"), 
          row.names=FALSE)

```

Plot the data points to see what they look like:

```{r}
map.pre <- map.sdbay.zm + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2008.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_point(data = pre.all,
             aes(x = Lon1, y = Lat1, color = ID.f),
             alpha = 0.5)+ 
  # geom_polygon(data = water.df,
  #              aes(x = long,
  #                  y = lat,
  #                  group = group),
  #              fill = "blue",
  #              alpha = 0.2) +

  #coord_map() + 
  #labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(legend.title = element_text(size = 10, hjust = 0.5),
        legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

plot(map.pre)
```



Do the same for post 

```{r}
dname <- "data/files_Apr2018_withNewTags/post/"
post.files <- dir(path = dname, 
                 pattern = "_inside_DayNight_4hrs_2018-07-11.csv")

post.IDs <- unlist(lapply(post.files, FUN = ID.names))

post.all <- do.call(rbind, 
                   lapply(post.files,
                          FUN = function(x) read.csv(paste0(dname, x)))) %>%
  mutate(ID.f = as.factor(ArgosID)) %>%
  filter(include == 1)

map.post <- map.sdbay.zm + 
   geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",
               #alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2014.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.6) +
  geom_point(data = post.all,
             aes(x = Lon1, y = Lat1, color = ID.f),
             alpha = 0.5)+ 
  labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        #legend.position = c(0.2, 0.5),
        legend.position = "none")

plot(map.post)
```

And probably we should inlude the new files into "post". Also, take out the one track that goes out the bay - north of 32.66N
```{r}
dname <- "data/files_Apr2018_withNewTags/new/"
new.files <- dir(path = dname, 
                 pattern = "_inside_DayNight_4hrs_2018-07-11.csv")

new.IDs <- unlist(lapply(new.files, FUN = ID.names))

new.all <- do.call(rbind, 
                   lapply(new.files,
                          FUN = function(x) read.csv(paste0(dname, x)))) %>%
   mutate(ID.f = as.factor(ArgosID)) %>%
 filter(include == 1)

post.all <- rbind(post.all, new.all) %>%
  filter(Lat1 < 32.66)

write.csv(post.all, paste0(dname, "Post_GPS_LC_all.csv"), 
          row.names=FALSE)

map.post <- map.sdbay.zm + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) + 
               #fill = "blue",
               #alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2014.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.6) +geom_point(data = post.all,
             aes(x = Lon1, y = Lat1, color = ID.f),
             alpha = 0.5)+ 
  labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        #legend.position = c(0.2, 0.5),
    legend.position = "none")

plot(map.post)
```

We have a lot more individuals from the post period than the pre, so we need to do something about that... especially for computing HRs. 


Section 3: Compute HRs
Get coordinates as a dataframe and make a spatial object
```{r}
# when trying to compute HR for each individual, some don't have enough data
# extract those with at least 100 data points:

pre.all %>% count(by = ArgosID) %>%
  filter(n > (min_n - 1)) %>%
  #dplyr::select(by) %>%
  rename(ArgosID = by) -> ID.pre.min_n

pre.list <- make.HR.dataset(pre.all, ID.pre.min_n, tagproj)
```

Do the same with post dataset - choose those with at least min_n data points. 

```{r}
post.all %>% count(by = ArgosID) %>%
  filter(n > (min_n - 1)) %>%
  #dplyr::select(by) %>%
  rename(ArgosID = by) -> ID.post.min_n

post.list <- make.HR.dataset(post.all, ID.post.min_n, tagproj)

```

Then the home range analysis starts here. First we need to figure out the smoothing parameter (bandwidth, h). There seem to be different methods and recommendations...

First, tru least-squares cross validation on the pre data:
```{r}
pre.kd.href <- kernelUD(pre.list$all.utm, 
                   h="href",  
                   grid=300,
                   kern = "bivnorm")

pre.kd.LSCV <- kernelUD(pre.list$all.utm, 
                        h="LSCV",  
                        hlim = c(0.03, 1.5), 
                        grid=300,
                        kern = "bivnorm")

plotLSCV(pre.kd.LSCV)

```

Referecne or optimum bandwidth is ~248 (see pre.kd.href), whereas the LSCV comes back with h = 25.9 (Pre.kd@h$h). According to Kie (2013), we should decrease href in increments of 0.10 and the best value is the smallest increment of href that 1. resulted in a contiguous rather than disjoint 95% kernel home-range polygon, and 2. contained no lacuna within the home range. 
```{r}
h.adhoc <- seq(from = 0.1, to = 0.9, by = 0.1) * pre.kd.href@h$h

pre.kd.adhoc <- vector(mode = "list", length = length(h.adhoc))
for (k in 1:length(h.adhoc)){
  pre.kd.adhoc[[k]] <- kernelUD(pre.list$all.utm, 
                                h = h.adhoc[k],  
                                grid = 300,
                                kern = "bivnorm")
  
}

# make dataframes of vertices:
pre.ver.95.adhoc <- lapply(pre.kd.adhoc, FUN = getverticeshr, percent = 95)

pre.ver.95.adhoc.tmp <- lapply(pre.ver.95.adhoc, 
                              FUN = spTransform, CRS = CRS("+proj=longlat"))

pre.ver.95.adhoc.list <- lapply(pre.ver.95.adhoc.tmp,
                               FUN = broom::tidy)

for (k in 1:length(pre.ver.95.adhoc.list)){
  pre.ver.95.adhoc.list[[k]] <- pre.ver.95.adhoc.list[[k]] %>% 
    mutate(h = h.adhoc[k]) %>%
    mutate(h.fac = as.factor(round(h, digits = 2)))
}

# rbind all:
pre.ver.95.adhoc.df <- do.call("rbind", pre.ver.95.adhoc.list)

p.h.adhoc.pre <- ggplot(data = pre.ver.95.adhoc.df,
                    aes(x = long, y = lat,
                        group = group)) + 
  geom_polygon() + 
  coord_map() + facet_grid(. ~ h.fac) +
  facet_wrap( ~ h.fac, ncol = 3) + 
  labs(x = "", y = "")

plot(p.h.adhoc.pre)

ggsave(filename = paste0("figures/HR_pre_h_comp_", Sys.Date(), ".png"),
       plot = p.h.adhoc.pre,
       dpi = 600,
       device = "png")
```

Looking at these plots, h = 125 may be okay for the pre dataset? 

```{r}
## Section 3.1.2
##Visually optimized hlim = c(0.565,1.5), grid=300
# grid values from 50 to 300 don't change the outcome;
# extent values from 1 to 200 don't change the outcome either

#LSCV estimated band width is too small and home range becomes fragmented
# so, I increased it to 100
h.pre <- 125

pre.HR <- HR.bvnorm.fcn(pre.list$all.utm, 
                        pre.list$byID.utm, 
                        h = h.pre, 
                        hlim=c(0.03, 1.5), 
                        grid=300, extent = 1)
pre.bw <- pre.HR$all.kd@h$h ##bandwidth estimate

pre.Area.50 <- pre.HR$area.all["50"]
pre.Area.95 <- pre.HR$area.all["95"]

pre.ver.50 <- getverticeshr(pre.HR$all.kd, 50)
pre.ver.95 <- getverticeshr(pre.HR$all.kd, 95)

# plot(pre.ver.50, axes = TRUE)
# plot(pre.ver.95, axes = TRUE)
#points(pre.all.utm, col="blue")

```


Do the same for the post data - here we need to look at subsampling individuals. First, use all data.

```{r}
post.kd.adhoc <- vector(mode = "list", length = length(h.adhoc))
for (k in 1:length(h.adhoc)){
  post.kd.adhoc[[k]] <- kernelUD(post.list$all.utm, 
                                h = h.adhoc[k],  
                                grid = 300,
                                kern = "bivnorm")
  
}

# make dataframes of vertices:
post.ver.95.adhoc <- lapply(post.kd.adhoc, FUN = getverticeshr, percent = 95)

post.ver.95.adhoc.tmp <- lapply(post.ver.95.adhoc, 
                              FUN = spTransform, CRS = CRS("+proj=longlat"))

post.ver.95.adhoc.list <- lapply(post.ver.95.adhoc.tmp,
                               FUN = broom::tidy)

for (k in 1:length(post.ver.95.adhoc.list)){
  post.ver.95.adhoc.list[[k]] <- post.ver.95.adhoc.list[[k]] %>% 
    mutate(h = h.adhoc[k]) %>%
    mutate(h.fac = as.factor(round(h, digits = 2)))
}

# rbind all:
post.ver.95.adhoc.df <- do.call("rbind", post.ver.95.adhoc.list)

p.h.adhoc.post <- ggplot(data = post.ver.95.adhoc.df,
                    aes(x = long, y = lat,
                        group = group)) + 
  geom_polygon() + 
  coord_map() + facet_grid(. ~ h.fac) +
  facet_wrap( ~ h.fac, ncol = 3) + 
  labs(x = "", y = "")

plot(p.h.adhoc.post)

ggsave(filename = paste0("figures/HR_post_h_comp_", Sys.Date(), ".png"),
       plot = p.h.adhoc.post,
       dpi = 600,
       device = "png")
```

For post data, h = 100 may be okay?


```{r}
## Section 3.1.2
##Visually optimized hlim = c(0.565,1.5), grid=300
h.post <- 150
post.HR <- HR.bvnorm.fcn(all.utm = post.list$all.utm, 
                         byID.utm = post.list$byID.utm, 
                         h = h.post, 
                         hlim=c(0.03, 1.5), 
                         grid=300, extent = 1)
post.bw <- post.HR$all.kd@h$h ##bandwidth estimate

post.Area.50 <- post.HR$area.all["50"]
post.Area.95 <- post.HR$area.all["95"]

post.ver.50 <- getverticeshr(post.HR$all.kd, 50)
post.ver.95 <- getverticeshr(post.HR$all.kd, 95)

# plot(post.ver.50, axes = TRUE)
# plot(post.ver.95, axes = TRUE)
#points(pre.all.utm, col="blue")
```

Select all possible combinations of 6 (ID.pre.min_n) individuals from the post data. There are 8008 possible combinations when min_n = 50. It takes a bit of time, I select 1000 of them. Because of the sample size decreases, I use h.pre for this.

```{r}
combos <- combn(1:dim(ID.post.min_n)[1], dim(ID.pre.min_n)[1]) 
combos <- combos[, sample(1:ncol(combos), size = 1000)]
IDs <- vector(mode = "list", length = ncol(combos))
area.95 <- area.50 <- vector(mode = "numeric", length = ncol(combos))

#p.list <- list()
for (k in 1:ncol(combos)){
  
  ID.post.tmp <- ID.post.min_n[combos[,k], ]
  tmp.list <- make.HR.dataset(post.all, ID.post.tmp, tagproj)
  
  tmp.HR <- HR.bvnorm.fcn(all.utm = tmp.list$all.utm,
                          byID.utm = tmp.list$byID.utm,
                          h = h.post,
                          hlim=c(0.03, 1.5),
                          grid=300, extent = 1)
  
  tmp.df <- broom::tidy(spTransform(getverticeshr(tmp.HR$all.kd, 95), 
                               CRS("+proj=longlat"))) 
                   
  pts.df <- data.frame(lon = tmp.list$all.coords@coords[,1],
                       lat = tmp.list$all.coords@coords[,2])
  
  # p.list[[k]] <- ggplot() + 
  #   geom_polygon(data = tmp.df, aes(x = long, y = lat, group = group)) +
  #   geom_point(data = pts.df, aes(x = lon, y = lat),
  #              color = "green") + coord_map()

  area.50[k] <- tmp.HR$area.all["50"]
  area.95[k] <- tmp.HR$area.all["95"]

  IDs[[k]] <- ID.post.tmp[,1]
}

areas.combos <- list(area95 = area.95,
                     area50 = area.50,
                     ID = IDs)

saveRDS(areas.combos, file = "RData/areas_combos.rds")

#readRDS(file = "RData/areas_combos.rds")

```


Make a plot for pre:
```{r}

pre.ver.50.df <- broom::tidy(spTransform(pre.ver.50, CRS("+proj=longlat")))
pre.ver.95.df <- broom::tidy(spTransform(pre.ver.95, CRS("+proj=longlat")))

map.pre.HR <- map.sdbay.zm + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2008.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_polygon(data = pre.ver.95.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "cornsilk",
               alpha = 0.6) + 
  geom_polygon(data = pre.ver.50.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "red3",
               alpha = 0.6) + 
  # geom_point(data = pre.all,
  #            aes(x = Lon1, y = Lat1),
  #            alpha = 0.5,
  #            size = 0.2)+ 
  # geom_polygon(data = water.df,
  #              aes(x = long,
  #                  y = lat,
  #                  group = group),
  #              fill = "blue",
  #              alpha = 0.2) +

  #coord_map() + 
  #labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")


#plot(map.pre.HR)
```

Make a plot for post using all data:
```{r}

post.ver.50.df <- broom::tidy(spTransform(post.ver.50, CRS("+proj=longlat")))
post.ver.95.df <- broom::tidy(spTransform(post.ver.95, CRS("+proj=longlat")))

map.post.HR <- map.sdbay.zm + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2014.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_polygon(data = post.ver.95.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "cornsilk",
               alpha = 0.6) + 
  geom_polygon(data = post.ver.50.df,
               aes(x = long, y = lat, 
                   group = group),
               fill = "red3",
               alpha = 0.6) + 
  # geom_point(data = post.all,
  #            aes(x = Lon1, y = Lat1),
  #            alpha = 0.5,
  #            size = 0.2)+ 
  # # geom_polygon(data = water.df,
  #              aes(x = long,
  #                  y = lat,
  #                  group = group),
  #              fill = "blue",
  #              alpha = 0.2) +

  #coord_map() + 
  #labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

ggsave(filename = paste0("figures/HR_pre_h100_", Sys.Date(), ".png"),
       plot = map.pre.HR,
       dpi = 600,
       device = "png")

ggsave(filename = paste0("figures/HR_post_h100_", Sys.Date(), ".png"),
       plot = map.post.HR,
       dpi = 600,
       device = "png")
#plot(map.post.HR)
```