---
title: "Home range analysis for green turtles in San Diego Bay (2019-10-31)"
output: html_notebook
---

San Diego Bay Turtle Movement Analysis
Original R Code, JT Froeschke, December 29, 2015
Data modified from previous versions by SE Graham, June 2016, May 2018
Data modified from May 2018 by T EGuchi, July 2018

Filtered data utilize GPS, and Argos LC = 1,2,3
Filtered data do not include points on land
Filtered data only allow for 1 relocation every 4 horus

Purpose of the script is to compute homerange (area) using 
least squares cross-validation including 50% and 95% contours.
An analysis of each turtle and an aggregate pre and post will be computed
h values are chosen based on best judgment and gst behavior  

2019-10-31: For this revision, GPS and Argos locations are split, as per a reviewer's suggestion. In order to put all analysis in one, I redo all the steps. 

```{r}
rm(list = ls())

#Section 1: Load libraries and set wd
#library(readxl)
library(tidyverse)
library(adehabitatHR)
library(rgdal)
library(leaflet) 
library(ggplot2)
library(lubridate)
library(StreamMetabolism)

# The date the first few chunks were run to find inside/outside, day/night, and split into 4-hr blocks. 
run.date <- "2019-11-01"
save.figure <- F

# Minimum number of relocations per individual to be included in HR analysis
min_n <- 50
#N.end <- 32.69   # approx Coronado bridge
N.end <- 32.66 # changed from 32.69 because 152314 had a gap in data points between ~32.65 and ~32.66 - seems like there was a different behavior south and north of 32.66
grid.value <- 1000

# max residual value
res.limit <- 35.0

LCs<-c("1","2","3")

source("HR_analysis_fcns.R")

```


Section 2: read in data

First, read the raw data and find whether or not each location is inside or outside SDB. 

```{r}

dNames <- paste0("data/files_Oct2019_withNewTags/", c("pre", "post", "new"))
SDBay <- read.csv("data/SDBay_polygon.csv")

for (d in 1:length(dNames)){
  data.files <- dir(dNames[d], pattern = ".txt")
  
  for (k in 1:length(data.files)){
    if (!file.exists(paste0(dNames[d], "/", 
                            unlist(strsplit(data.files[k], '.txt'))[1],
                            "_inout.csv"))){
      dat <- read.csv(paste0(dNames[d], "/", data.files[k]))
      in.out <- vector(mode = "numeric", length = dim(dat)[1])
      for (k1 in 1:length(in.out)){
        in.out[k1] <- point.in.polygon(dat$Lon1[k1], dat$Lat1[k1],
                                       SDBay$long, SDBay$lat)
      }
      dat$inside <- in.out
      
      write.csv(dat,
                file = paste0(dNames[d], "/", 
                              unlist(strsplit(data.files[k], '.txt'))[1],
                              "_inout.csv"),
                quote = F, row.names = F)
      
      # inside SDB and also south of N.end (32.66 as of 16 Dec 2019)
      dat.inside <- filter(dat, inside == 1) %>% 
        filter(Lat1 < N.end)
      
      write.csv(dat.inside,
                file = paste0(dNames[d], "/", 
                              unlist(strsplit(data.files[k], '.txt'))[1],
                              "_inside.csv"),
                quote = F, row.names = F)
      
    }

    #plot(SDBay$long, SDBay$lat, type = 'l')
    #points(dat$Lon1[in.out == 1], dat$Lat1[in.out == 1], col = 'green')
    #points(dat$Lon1[in.out == 0], dat$Lat1[in.out == 0], col = 'red')
  }
  
}


```


Then do some Argos filtering both for inside and inout.

```{r}

# get the beginning and end dates of each data file
get.dates.1 <- function(data.file){
  data.file$Date1 <- as.POSIXct(strptime(data.file$TransmissionDateTime,
                                         "%m-%d-%Y %H:%M:%S"),
                                tz = "GMT")
  
  #data.file$Date2 <- as.character(data.file$Date, format = "%Y/%m/%d")
  date.begin <- min(data.file$Date, na.rm = T)
  date.end <- max(data.file$Date, na.rm = T)
  out <- list(begin = date.begin, end = date.end)
  return(out)
}

get.dates.2 <- function(data.file){
  data.file$Date <- as.POSIXct(strptime(data.file$TransmissionDateTime,
                                        "%m/%d/%Y %H:%M:%S"),
                               tz = "GMT")
  #data.file$Date2 <- as.character(data.file$Date, format = "%Y/%m/%d")
  date.begin <- min(data.file$Date, na.rm = T)
  date.end <- max(data.file$Date, na.rm = T)
  out <- list(begin = date.begin, end = date.end)
  return(out)
}

fix.date.1 <- function(x){
  x$UTCDateTime <- as.POSIXct(strptime(x$TransmissionDateTime,
                                       "%m-%d-%Y %H:%M:%S"),
                              tz = "GMT")
  return(x)
} 

fix.date.2 <- function(x){
  x$UTCDateTime <- as.POSIXct(strptime(x$TransmissionDateTime,
                                       "%m/%d/%Y %H:%M:%S"),
                              tz = "GMT")
  return(x)
}

dataset <- c("inside", "inout")
d <- k1 <- 1
for (d in 1:length(dNames)){
    
  for (k1 in 1:2){
    if (k1 == 1){
      all.files <- as.list(list.files(dNames[d], pattern = "_inside.csv"))
    } else {
      all.files <- as.list(list.files(dNames[d], pattern = "_inout.csv"))
    }

    IDs <- unlist(lapply(all.files, FUN = ID.names))
    if (!file.exists(paste0(dNames[d], "/", IDs[1], "_", dataset[k1], "_DayNight.csv"))){
      
      all.data <- lapply(all.files,
                         FUN = function(x) read.csv(paste0(dNames[d], "/", x)))
      
      if (d != 3){
        dates.begin.end <- lapply(all.data, FUN = get.dates.1)
        all.data <- lapply(all.data, FUN = fix.date.1)
        
      } else {
        dates.begin.end <- lapply(all.data, FUN = get.dates.2)
        all.data <- lapply(all.data, FUN = fix.date.2)
      }
      
      #filters each Argos tag for nums (LC 1,2,3) and GPS, which eliminates Argos A,B,Z,0
      ## | represents or
      # Also remove latitude that is >= N.end
      
      filtered.data <- lapply(all.data,
                              FUN = function(x){
                                x %>% 
                                  filter(LC %in% LCs | Message_Type=="GPS") %>%
                                  dplyr::select(ID, ArgosID, Message_Type,
                                                TransmissionDateTime, UTCDateTime,
                                                LC, Residual,
                                                Lat1, Lon1, inside) %>%
                                  filter(Lat1 < N.end) %>%
                                  mutate(LocalDateTime = with_tz(UTCDateTime,
                                                                 tzone = "America/Los_Angeles")) %>%
                                  mutate(Date2 = as.character(LocalDateTime,
                                                              format = "%Y/%m/%d")) %>%
                                  filter(!is.na(Lat1))})
      
      # then find sunrise/sunset for each line of the data files:
      filtered.rise.set <- lapply(filtered.data,
                                  FUN = function(x){
                                    rise <- set <- vector(mode = "numeric",
                                                          length = dim(x)[1])
                                    
                                    for (k in 1:dim(x)[1]){
                                      tmp <- sunrise.set(lat = x$Lat1[k],
                                                         long = x$Lon1[k],
                                                         date = x$Date2[k],
                                                         timezone = "America/Los_Angeles")
                                      
                                      rise[k] <- tmp$sunrise
                                      set[k] <- tmp$sunset
                                    }
                                    
                                    x$LocalSunrise <- as.POSIXct(rise,
                                                                 origin = "1970-01-01 00:00.00 UTC")
                                    x$LocalSunset <- as.POSIXct(set,
                                                                origin = "1970-01-01 00:00.00 UTC")
                                    
                                    x$day1night2 <- ifelse((x$LocalDateTime > x$LocalSunrise &
                                                              x$LocalDateTime < x$LocalSunset),
                                                           1, 2)
                                    return(x)
                                  })
      
      for (k in 1:length(filtered.rise.set)){
        
          outfile <- paste0(dNames[d], "/", IDs[k], "_", dataset[k1], "_DayNight.csv")
          write.csv(filtered.rise.set[[k]],
                    file = outfile,
                    quote = F, 
                    row.names=F)
          
      }
    }
  }
  
}

```
  
Split the data into GPS or ARGOS first, then, split them into 4-hour segments. 

```{r}
d <- k0 <- k1 <- k2 <- 1
for (d in 1:length(dNames)){
  all.files <- dir(dNames[d], "_inside_DayNight")
  
  for (k0 in 1:length(all.files)){
    id <- unlist(strsplit(all.files[k0], '_'))[1]
    
    fileout.gps <- paste0(dNames[d], '/', id, "_inside_DayNight_4hrs_GPS.csv")

    fileout.argos <- paste0(dNames[d], '/', id, "_inside_DayNight_4hrs_ARGOS.csv")

    if (!file.exists(paste0(dNames[d], '/', id, "_inside_DayNight_4hrs_GPS.csv"))){
      dat <- read.csv(paste0(dNames[d], '/', all.files[k0]))
      
      # create hours column:
      dat$hr <- hour(dat$LocalDateTime)
      
      # GPS data need to be residual <= 35.0
      dat %>% filter(Message_Type == "GPS") %>% filter(Residual <= 35) -> dat.gps
      dat %>% filter(Message_Type != "GPS") -> dat.argos
      
      write(x = colnames(dat), file = fileout.gps,
            sep = ",", ncolumns = dim(dat.gps)[2])
      
      write(x = colnames(dat), file = fileout.argos,
            sep = ",", ncolumns = dim(dat.argos)[2])
      
      files <- c(fileout.gps, fileout.argos)
      dat.list <- list(dat.gps, dat.argos)
      
      for (k2 in 1:2){
        dat <- dat.list[[k2]]
        
        # we need to know which dates we have
        # use Y/m/d column
        uniq.dates <- levels(dat$Date2)
        for (k in 1:length(uniq.dates)){
          tmp1 <- dat[dat$Date2 == uniq.dates[k],]
          # then split into four-hr segments:
          # 0-4, 4-8, 8-12, 12-16, 16-20, 20-24
          for (k1 in 1:6){
            tmp2 <- tmp1[tmp1$hr >= ((k1-1) * 4) & tmp1$hr < (k1*4), ]
            if (dim(tmp2)[1] != 0){
              if (k2 == 1){
                res.num <- as.numeric(tmp2$Residual)
                ifelse(res.num <= res.limit,
                       tmp3 <- tmp2[res.num == min(res.num),],
                       tmp3 <- NA)
                
              } else {
                LC.num <- as.numeric(tmp2$LC)
                tmp3 <- tmp2[LC.num == max(LC.num),]
              }
              
              if (length(tmp3) > 1){
                write.table(tmp3[1,], file = files[[k2]], sep = ",",
                            append = T, quote = F, col.names = F,
                            row.names = F)
                
              }
            }
          }
          
        }
      }
      
    }
  }
}

```

Section 2.1: Pre

In this chunk, I summarize how many of data points were removed for each telemetry method (GPS and ARGOS). So, I need to use the original and filtered data. 

```{r}
pre.summary <- get.summary.1(dNames[1])

#if (!file.exists("data/pre_sample_summary.csv"))
  write.csv(pre.summary$raw.summary,
            "data/pre_sample_summary.csv",
            row.names = F, 
            quote = F)

#if (!file.exists("data/pre_sample_GPS_summary.csv"))
  write.csv(pre.summary$GPS.summary, 
            "data/pre_sample_GPS_summary.csv",
            row.names = F,
            quote = F)

#if (!file.exists("data/pre_sample_ARGOS_summary.csv"))
  write.csv(pre.summary$ARGOS.summary, 
            "data/pre_sample_ARGOS_summary.csv",
            row.names = F,
            quote = F)

#if (!file.exists("data/pre_GPS_all.csv"))
  write.csv(pre.summary$GPS,
            "data/pre_GPS_all.csv",
            row.names = F,
            quote = F)

#if (!file.exists("data/pre_ARGOS_all.csv"))
  write.csv(pre.summary$ARGOS,
            "data/pre_ARGOS_all.csv",
            row.names = F,
            quote = F)

```

Plot the data points to see what they look like:

Get some base layer maps here:

```{r}
# just use the 2014 eelgrass data - there are old data files also
SDBay.eelg.2014 <- spTransform(readOGR(dsn = "GISfiles/Features",
                                       layer = "SD_Baywide_Eelgrass_2014_Final",
                                       verbose = F),
                               CRS("+proj=longlat +datum=WGS84"))
SDBay.eelg.2014.df <- broom::tidy(SDBay.eelg.2014)

SDBay.eelg.2008 <- spTransform(readOGR(dsn = "GISfiles/Features",
                                       layer = "SD_Baywide_Eelgrass_2008",
                                       verbose = F),
                               CRS("+proj=longlat +datum=WGS84"))
SDBay.eelg.2008.df <- broom::tidy(SDBay.eelg.2008)


sdbay.all <- readRDS(file = 'RData/sdbay_all.rds')
sdbay.south <- readRDS(file = 'RData/sdbay_south.rds')
sdbay.med <- readRDS(file = 'RData/sdbay_med.rds')

map.sdbay.zm <- ggmap::ggmap(sdbay.all)

map.sdbay.south <- ggmap::ggmap(sdbay.south)

map.sdbay.med <- ggmap::ggmap(sdbay.med)

# read in the SDB shape file:
SDB.shape <- readOGR(dsn = "GISfiles", layer = "sd_bay")
SDBay <- spTransform(readOGR(dsn = "GISfiles",
                             layer = "sd_bay",
                             verbose = F),
                     CRS("+proj=longlat +datum=WGS84"))
SDBay.df <- broom::tidy(SDBay)

water <- spTransform(readOGR(dsn = "GISfiles", 
                             layer = "water",
                             verbose = F),
                     CRS("+proj=longlat +datum=WGS84"))
water.df <- broom::tidy(water) %>%
  filter(lat < 32.75 & lat > 32.58 & long > -117.25)

tagprj <- readOGR(dsn = "Tag_065_UTMzone11n", 
                  layer = "tag_065_project")
tagproj <- proj4string(tagprj)

# not sure what this part is doing... 
latlong = "+init=epsg:4326"

water.color <- "lightblue"
background.color <- "darkgray"
xlim <- c(-117.145, -117.09)
ylim <- c(32.595, 32.665)
  
```

```{r}
map.pre <- map.sdbay.zm + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2008.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_point(data = pre.summary$raw,
             aes(x = Lon1, y = Lat1, color = ID.f),
             alpha = 0.5)+ 
  xlab('Longitude') + ylab('Latitude') + 
  theme(legend.title = element_text(size = 10, hjust = 0.5),
        legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/map_pre_raw.png",
         plot = map.pre,
         device = "png",
         dpi = 600)
plot(map.pre)

```

Next plot is using only GPS data that were included in the analysis. Note no data points north of 32.66N. 

```{r}
map.pre.GPS <- map.sdbay.zm + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2008.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_point(data = pre.summary$GPS,
             aes(x = Lon1, y = Lat1, color = ID.f),
             alpha = 0.5)+ 
  xlab('Longitude') + ylab('Latitude') + 
  theme(legend.title = element_text(size = 10, hjust = 0.5),
        legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/map_pre_GPS.png",
         plot = map.pre.GPS,
         device = "png",
         dpi = 600)
plot(map.pre.GPS)
```

Next plot is using only ARGOS data that were included in the analysis:

```{r}
map.pre.ARGOS <- map.sdbay.zm + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2008.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_point(data = pre.summary$ARGOS,
             aes(x = Lon1, y = Lat1, color = ID.f),
             alpha = 0.5)+ 
  xlab('Longitude') + ylab('Latitude') + 
  theme(legend.title = element_text(size = 10, hjust = 0.5),
        legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/map_pre_ARGOS.png",
         plot = map.pre.ARGOS,
         device = "png",
         dpi = 600)
plot(map.pre.ARGOS)
```

Do the same with the post datasets. And probably we should inlude the new files into "post". Also, take out the one track that goes out the bay - north of 32.66N

```{r}

post.summary <- get.summary.1(dNames[2])
new.summary <- get.summary.1(dNames[3], date.format = "%m/%d/%Y %H:%M:%S")

post.all <- rbind(post.summary$raw, new.summary$raw) %>%
  filter(Lat1 < 32.66)
post.GPS <- rbind(post.summary$GPS, new.summary$GPS) %>%
  filter(Lat1 < 32.66) 
post.ARGOS <- rbind(post.summary$ARGOS, new.summary$ARGOS) %>%
  filter(Lat1 < 32.66)

#if (!file.exists("data/post_sample_summary.csv"))
  write.csv(rbind(post.summary$raw.summary, new.summary$raw.summary),
            "data/post_sample_summary.csv",
            row.names = F, 
            quote = F)

#if (!file.exists("data/post_sample_GPS_summary.csv"))
  write.csv(rbind(post.summary$GPS.summary, new.summary$GPS.summary), 
            "data/post_sample_GPS_summary.csv",
            row.names = F,
            quote = F)

#if (!file.exists("data/post_sample_ARGOS_summary.csv"))
  write.csv(rbind(post.summary$ARGOS.summary, new.summary$ARGOS.summary), 
            "data/post_sample_ARGOS_summary.csv",
            row.names = F,
            quote = F)

#if (!file.exists("data/post_GPS_all.csv"))
  write.csv(post.GPS,
            "data/post_GPS_all.csv",
            row.names = F,
            quote = F)

#if (!file.exists("data/post_ARGOS_all.csv"))
  write.csv(post.ARGOS,
            "data/post_ARGOS_all.csv",
            row.names = F,
            quote = F)

```

Next plot uses all data points. 

```{r}

map.post <- map.sdbay.zm + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) + 
               #fill = "blue",
               #alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2014.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.6) +
  geom_point(data = post.all,
             aes(x = Lon1, y = Lat1, color = ID.f),
             alpha = 0.5)+ 
  labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        #legend.position = c(0.2, 0.5),
    legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/map_post_raw_2.png",
         plot = map.post,
         device = "png",
         dpi = 600)

plot(map.post)
```

Next plot uses filtered data. 

```{r}
map.post.GPS <- map.sdbay.zm + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2008.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_point(data = post.GPS,
             aes(x = Lon1, y = Lat1, color = ID.f),
             alpha = 0.5)+ 
  xlab('Longitude') + ylab('Latitude') + 
  theme(legend.title = element_text(size = 10, hjust = 0.5),
        legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/map_post_GPS.png",
         plot = map.post.GPS,
         device = "png",
         dpi = 600)
plot(map.post.GPS)
```

Next plot is using only ARGOS data that were included in the analysis:

```{r}
map.post.ARGOS <- map.sdbay.zm + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2008.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_point(data = post.ARGOS,
             aes(x = Lon1, y = Lat1, color = ID.f),
             alpha = 0.5)+ 
  xlab('Longitude') + ylab('Latitude') + 
  theme(legend.title = element_text(size = 10, hjust = 0.5),
        legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/map_post_ARGOS.png",
         plot = map.post.ARGOS,
         device = "png",
         dpi = 600)
plot(map.post.ARGOS)
```


We have a lot more individuals from the post period than the pre, so we need to do something about that... especially for computing HRs. 


Section 3: Compute HRs

```{r}
# when trying to compute HR for each individual, some don't have enough data
# extract those with at least 50 data points:

pre.GPS.kd <- HR.analysis.step1(min_n, pre.summary$GPS, tagproj, grid = grid.value)
pre.ARGOS.kd <- HR.analysis.step1(min_n, pre.summary$ARGOS, tagproj, grid = grid.value)
```
The algorithm does not converge for ARGOS data.

Do the same with post dataset - choose those with at least min_n data points. 

```{r}
post.GPS.kd <- HR.analysis.step1(min_n, post.GPS, tagproj, grid = grid.value)
post.ARGOS.kd <- HR.analysis.step1(min_n, post.ARGOS, tagproj, grid = grid.value)
```

The algorithm does not converge for ARGOS data for the LSCV method.  So, I will not use it. 

Then the home range analysis starts here. First we need to figure out the smoothing parameter (bandwidth, h). There seem to be different methods and recommendations...

First, least-squares cross validation on the pre GPS data:
```{r}
plotLSCV(pre.GPS.kd$kd.LSCV)

```

Looking at the GPS data, referecne or optimum bandwidth is ~248 (see pre.GPS.kd\$kd.href@h), whereas the LSCV comes back with h = 30.1 (pre.GPS.kd\$kd.LSCV@h). According to Kie (2013), we should decrease href in increments of 0.10 and the best value is the smallest increment of href that 1. resulted in a contiguous rather than disjoint 95% kernel home-range polygon, and 2. contained no lacuna within the home range. 

Looking at these plots, multiplier = 0.4 may be the smallest value with a contiguous 95% UD.  This is found in pre.GPS.HR$h.1 below. 

```{r}
h.multiplier <-  seq(from = 0.1, to = 0.95, by = 0.05) 

pre.GPS.HR <- run.HR.analysis(pre.GPS.kd, 
                              "pre_GPS", 
                              grid.value, 
                              h.multiplier, 
                              shape.file.dir = "shapefiles_Nov2019/")

saveRDS(pre.GPS.HR,
        file = "RData/pre_GPS_UD.rds")

# remove the land area. 
area.pre.GPS.50 <- get.area.UTM(pre.GPS.HR$HR$ver.50)
area.pre.GPS.95 <- get.area.UTM(pre.GPS.HR$HR$ver.95)

# This HR is with the h value with the adhoc method
plot(pre.GPS.HR$h.adhoc$figure)

if (save.figure)
  ggsave(filename = "figures/UD95_pre_GPS_h_adhoc.png",
         plot = pre.GPS.HR$h.adhoc$figure,
         device = "png",
         dpi = 600)

```


I see there is a problem in plotting because of the boundary is a bit too small... Extending the southern end of the limits in the function fixed it.  

For ARGOS data , the multiplier of 0.7 makes a contiguous 95% HR (pre.ARGOS.HR$h.1). 

```{r}
pre.ARGOS.HR <- run.HR.analysis(pre.ARGOS.kd, 
                                "pre_ARGOS", 
                                grid.value, 
                                h.multiplier, 
                                shape.file.dir = "shapefiles_Nov2019/")

saveRDS(pre.ARGOS.HR,
        file = "RData/pre_ARGOS_UD.rds")

# remove the land area. 
area.pre.ARGOS.50 <- get.area.UTM(pre.ARGOS.HR$HR$ver.50)
area.pre.ARGOS.95 <- get.area.UTM(pre.ARGOS.HR$HR$ver.95)

plot(pre.ARGOS.HR$h.adhoc$figure)

if (save.figure)
  ggsave(filename = "figures/UD95_pre_ARGOS_h_adhoc.png",
         plot = pre.ARGOS.HR$h.adhoc$figure,
         device = "png",
         dpi = 600)
```


ARGOS data are not quite the same as GPS data. 

Do the same for the post data - here we need to look at subsampling individuals. First, use all data.

First, least-squares cross validation on the pre data:
```{r}
plotLSCV(post.GPS.kd$kd.LSCV)

```

Looking at the GPS data, referecne or optimum bandwidth is ~252 (see post.GPS.kd\$kd.href@h), whereas the LSCV comes back with h = 30.5 (post.GPS.kd\$kd.LSCV@h). According to Kie (2013), we should decrease href in increments of 0.10 and the best value is the smallest increment of href that 1. resulted in a contiguous rather than disjoint 95% kernel home-range polygon, and 2. contained no lacuna within the home range. The multiplier of 0.55 makes it (post.GPS.HR$h.1)

```{r}
post.GPS.HR <- run.HR.analysis(post.GPS.kd, 
                               "post_GPS", 
                               grid.value, 
                               h.multiplier, 
                               shape.file.dir = "shapefiles_Nov2019/")

saveRDS(post.GPS.HR,
        file = "RData/post_GPS_UD.rds")

# remove the land area. 
area.post.GPS.50 <- get.area.UTM(post.GPS.HR$HR$ver.50)
area.post.GPS.95 <- get.area.UTM(post.GPS.HR$HR$ver.95)

plot(post.GPS.HR$h.adhoc$figure)

if (save.figure)
  ggsave(filename = "figures/UD95_post_GPS_h_adhoc.png",
         plot = post.GPS.HR$h.adhoc$figure,
         device = "png",
         dpi = 600)

```



```{r}
post.ARGOS.HR <- run.HR.analysis(post.ARGOS.kd, 
                                 "post_ARGOS", 
                                 grid.value, 
                                 h.multiplier, 
                                 shape.file.dir = "shapefiles_Nov2019/")
saveRDS(post.ARGOS.HR,
        file = "RData/post_ARGOS_UD.rds")

# remove the land area. 
area.post.ARGOS.50 <- get.area.UTM(post.ARGOS.HR$HR$ver.50)
area.post.ARGOS.95 <- get.area.UTM(post.ARGOS.HR$HR$ver.95)

plot(post.ARGOS.HR$h.adhoc$figure)

if (save.figure)
  ggsave(filename = "figures/UD95_post_ARGOS_h_adhoc.png",
         plot = post.ARGOS.HR$h.adhoc$figure,
         device = "png",
         dpi = 600)
```

The multiplier of 0.45 makes a contiguous 95% HR (post.ARGOS.HR$h.1). 


Compare between night and day and pre and post:
```{r}
# pre day vs pre night:
pre.summary$GPS %>% filter(day1night2 == 1) -> pre.GPS.day
pre.GPS.kd.day <- HR.analysis.step1(min_n, pre.GPS.day, tagproj, grid = grid.value)

pre.summary$ARGOS %>% filter(day1night2 == 1) -> pre.ARGOS.day
pre.ARGOS.kd.day <- HR.analysis.step1(min_n, pre.ARGOS.day, tagproj, grid = grid.value)

plotLSCV(pre.GPS.kd.day$kd.LSCV)
```

```{r}
pre.GPS.HR.day <- run.HR.analysis(pre.GPS.kd.day, 
                                  "pre_GPS_day", 
                                  grid.value, 
                                  h.multiplier, 
                                  shape.file.dir = "shapefiles_Nov2019/")

saveRDS(pre.GPS.HR.day,
        file = "RData/pre_GPS_UD_day.rds")

# remove the land area. 
area.pre.GPS.day.50 <- get.area.UTM(pre.GPS.HR.day$HR$ver.50)
area.pre.GPS.day.95 <- get.area.UTM(pre.GPS.HR.day$HR$ver.95)


plot(pre.GPS.HR.day$h.adhoc$figure)

if (save.figure)
  ggsave(filename = "figures/UD95_pre_GPS_h_adhoc_day.png",
         plot = pre.GPS.HR.day$h.adhoc$figure,
         device = "png",
         dpi = 600)

```

multiplier = 0.5 may be good. See pre.GPS.HR.day$h.1.

For ARGOS data,

```{r}
pre.ARGOS.HR.day <- run.HR.analysis(pre.ARGOS.kd.day, 
                                    "pre_ARGOS_day", 
                                    grid.value, 
                                    h.multiplier, 
                                    shape.file.dir = "shapefiles_Nov2019/")

saveRDS(pre.ARGOS.HR.day,
        file = "RData/pre_ARGOS_UD_day.rds")

# remove the land area. 
area.pre.ARGOS.day.50 <- get.area.UTM(pre.ARGOS.HR.day$HR$ver.50)
area.pre.ARGOS.day.95 <- get.area.UTM(pre.ARGOS.HR.day$HR$ver.95)


plot(pre.ARGOS.HR.day$h.adhoc$figure)

if (save.figure)
  ggsave(filename = "figures/UD95_pre_ARGOS_h_adhoc_day.png",
         plot = pre.ARGOS.HR.day$h.adhoc$figure,
         device = "png",
         dpi = 600)

```

For the ARGOS data, h = 216.1 and the minimum muliplier is 0.75. (pre.ARGOS.HR.day$h.1) 


For night:
```{r}
pre.summary$GPS %>% filter(day1night2 == 2) -> pre.GPS.night
pre.GPS.kd.night <- HR.analysis.step1(min_n, pre.GPS.night, tagproj, grid = grid.value)

pre.summary$ARGOS %>% filter(day1night2 == 2) -> pre.ARGOS.night
pre.ARGOS.kd.night <- HR.analysis.step1(min_n, pre.ARGOS.night, tagproj, grid = grid.value)

plotLSCV(pre.GPS.kd.night$kd.LSCV)

```

```{r}
pre.GPS.HR.night <- run.HR.analysis(pre.GPS.kd.night, 
                                    "pre_GPS_night", 
                                    grid.value, 
                                    h.multiplier, 
                                    shape.file.dir = "shapefiles_Nov2019/")

saveRDS(pre.GPS.HR.night,
        file = "RData/pre_GPS_UD_night.rds")

# remove the land area. 
area.pre.GPS.night.50 <- get.area.UTM(pre.GPS.HR.night$HR$ver.50)
area.pre.GPS.night.95 <- get.area.UTM(pre.GPS.HR.night$HR$ver.95)

plot(pre.GPS.HR.night$h.adhoc$figure)

if (save.figure)
  ggsave(filename = "figures/UD95_pre_GPS_h_adhoc_night.png",
         plot = pre.GPS.HR.night$h.adhoc$figure,
         device = "png",
         dpi = 600)
```

multiplier = 0.55 may be good. See pre.GPS.HR.night$h.1.  


```{r}
pre.ARGOS.HR.night <- run.HR.analysis(pre.ARGOS.kd.night, 
                                    "pre_ARGOS_night", 
                                    grid.value, 
                                    h.multiplier, 
                                    shape.file.dir = "shapefiles_Nov2019/")
saveRDS(pre.ARGOS.HR.night,
        file = "RData/pre_ARGOS_UD_night.rds")

# remove the land area. 
area.pre.ARGOS.night.50 <- get.area.UTM(pre.ARGOS.HR.night$HR$ver.50)
area.pre.ARGOS.night.95 <- get.area.UTM(pre.ARGOS.HR.night$HR$ver.95)

plot(pre.ARGOS.HR.night$h.adhoc$figure)

if (save.figure)
  ggsave(filename = "figures/UD95_pre_ARGOS_h_adhoc_night.png",
         plot = pre.ARGOS.HR.night$h.adhoc$figure,
         device = "png",
         dpi = 600)
```

For the night, esimated h is 238.3 and the minimum multiplier is 0.75.  

Do the same with the post period
```{r}
# pre day vs pre night:
post.summary$GPS %>% filter(day1night2 == 1) -> post.GPS.day

post.GPS.kd.day <- HR.analysis.step1(min_n, post.GPS.day, tagproj, grid = grid.value)

post.summary$ARGOS %>% filter(day1night2 == 1) -> post.ARGOS.day

post.ARGOS.kd.day <- HR.analysis.step1(min_n, post.ARGOS.day, tagproj, grid = grid.value)

plotLSCV(post.GPS.kd.day$kd.LSCV)
```

```{r}
post.GPS.HR.day <- run.HR.analysis(post.GPS.kd.day, 
                                   "post_GPS_day", 
                                   grid.value, 
                                   h.multiplier, 
                                   shape.file.dir = "shapefiles_Nov2019/")

saveRDS(post.GPS.HR.day,
        file = "RData/post_GPS_UD_day.rds")

# remove the land area. 
area.post.GPS.day.50 <- get.area.UTM(post.GPS.HR.day$HR$ver.50)
area.post.GPS.day.95 <- get.area.UTM(post.GPS.HR.day$HR$ver.95)

plot(post.GPS.HR.day$h.adhoc$figure)
if (save.figure)
  ggsave(filename = "figures/UD95_post_GPS_h_adhoc_day.png",
         plot = post.GPS.HR.day$h.adhoc$figure,
         device = "png",
         dpi = 600)
```

multiplier = 0.5 may be good. See post.GPS.HR.day$h.1  


```{r}
post.ARGOS.HR.day <- run.HR.analysis(post.ARGOS.kd.day, 
                                     "post_ARGOS_day", 
                                     grid.value, 
                                     h.multiplier, 
                                     shape.file.dir = "shapefiles_Nov2019/")

saveRDS(post.ARGOS.HR.day,
        file = "RData/post_ARGOS_UD_day.rds")

# remove the land area. 
area.post.ARGOS.day.50 <- get.area.UTM(post.ARGOS.HR.day$HR$ver.50)
area.post.ARGOS.day.95 <- get.area.UTM(post.ARGOS.HR.day$HR$ver.95)

plot(post.ARGOS.HR.day$h.adhoc$figure)
if (save.figure)
  ggsave(filename = "figures/UD95_post_ARGOS_h_adhoc_day.png",
         plot = post.ARGOS.HR.day$h.adhoc$figure,
         device = "png",
         dpi = 600)
```

Estimated h is 147.5 and the minimum multiplier is 0.5. 

For night:
```{r}
post.summary$GPS %>% filter(day1night2 == 2) -> post.GPS.night
post.GPS.kd.night <- HR.analysis.step1(min_n, post.GPS.night, tagproj, grid = grid.value)

post.summary$ARGOS %>% filter(day1night2 == 2) -> post.ARGOS.night
post.ARGOS.kd.night <- HR.analysis.step1(min_n, post.ARGOS.night, tagproj, grid = grid.value)

plotLSCV(post.GPS.kd.night$kd.LSCV)

```

```{r}
post.GPS.HR.night <- run.HR.analysis(post.GPS.kd.night, 
                                     "post_GPS_night", 
                                     grid.value, 
                                     h.multiplier, 
                                     shape.file.dir = "shapefiles_Nov2019/")

saveRDS(post.GPS.HR.night,
        file = "RData/post_GPS_UD_night.rds")

# remove the land area. 
area.post.GPS.night.50 <- get.area.UTM(post.GPS.HR.night$HR$ver.50)
area.post.GPS.night.95 <- get.area.UTM(post.GPS.HR.night$HR$ver.95)

plot(post.GPS.HR.night$h.adhoc$figure)
if (save.figure)
  ggsave(filename = "figures/UD95_post_GPS_h_adhoc_night.png",
         plot = post.GPS.HR.night$h.adhoc$figure,
         device = "png",
         dpi = 600)
```

multiplier = 0.5 may be good. See post.GPS.HR.night$h.1  

```{r}
post.ARGOS.HR.night <- run.HR.analysis(post.ARGOS.kd.night, 
                                       "post_ARGOS_night", 
                                       grid.value, 
                                       h.multiplier, 
                                       shape.file.dir = "shapefiles_Nov2019/")

saveRDS(post.ARGOS.HR.night,
        file = "RData/post_ARGOS_UD_night.rds")

# remove the land area. 
area.post.ARGOS.night.50 <- get.area.UTM(post.ARGOS.HR.night$HR$ver.50)
area.post.ARGOS.night.95 <- get.area.UTM(post.ARGOS.HR.night$HR$ver.95)

plot(post.ARGOS.HR.night$h.adhoc$figure)
if (save.figure)
  ggsave(filename = "figures/UD95_post_ARGOS_h_adhoc_night.png",
         plot = post.ARGOS.HR.night$h.adhoc$figure,
         device = "png",
         dpi = 600)
```

Estimated h is 229.8 and the minimum multiplier of 0.85. See post.ARGOS.HR.night$h.1 

Combine results together to compare pre and post UDs.  

```{r}
UD.df <- data.frame(period = rep(c("pre", "pre", "pre", "post", "post", "post"), 4),
                    day_night = rep(c("all", "day", "night"), 8),
                    UD = rep(c(rep(50, 6), rep(95, 6)), 2),
                    source = c(rep("GPS", 12), rep("ARGOS", 12)),
                    area = c(pre.GPS.HR$HR$area.50, 
                             pre.GPS.HR.day$HR$area.50, 
                             pre.GPS.HR.night$HR$area.50,
                             post.GPS.HR$HR$area.50, 
                             post.GPS.HR.day$HR$area.50, 
                             post.GPS.HR.night$HR$area.50,
                             pre.GPS.HR$HR$area.95, 
                             pre.GPS.HR.day$HR$area.95, 
                             pre.GPS.HR.night$HR$area.95,
                             post.GPS.HR$HR$area.95, 
                             post.GPS.HR.day$HR$area.95, 
                             post.GPS.HR.night$HR$area.95,
                             pre.ARGOS.HR$HR$area.50, 
                             pre.ARGOS.HR.day$HR$area.50, 
                             pre.ARGOS.HR.night$HR$area.50,
                             post.ARGOS.HR$HR$area.50, 
                             post.ARGOS.HR.day$HR$area.50, 
                             post.ARGOS.HR.night$HR$area.50,
                             pre.ARGOS.HR$HR$area.95, 
                             pre.ARGOS.HR.day$HR$area.95, 
                             pre.ARGOS.HR.night$HR$area.95,
                             post.ARGOS.HR$HR$area.95, 
                             post.ARGOS.HR.day$HR$area.95, 
                             post.ARGOS.HR.night$HR$area.95),
                    areaNoLand = c(slot(area.pre.GPS.50@polygons[[1]], "area")/1000000,
                                   slot(area.pre.GPS.day.50@polygons[[1]], "area")/1000000,
                                   slot(area.pre.GPS.night.50@polygons[[1]], "area")/1000000,
                                   slot(area.post.GPS.50@polygons[[1]], "area")/1000000,
                                   slot(area.post.GPS.day.50@polygons[[1]], "area")/1000000,
                                   slot(area.post.GPS.night.50@polygons[[1]], "area")/1000000,
                                   slot(area.pre.GPS.95@polygons[[1]], "area")/1000000,
                                   slot(area.pre.GPS.day.95@polygons[[1]], "area")/1000000,
                                   slot(area.pre.GPS.night.95@polygons[[1]], "area")/1000000,
                                   slot(area.post.GPS.95@polygons[[1]], "area")/1000000,
                                   slot(area.post.GPS.day.95@polygons[[1]], "area")/1000000,
                                   slot(area.post.GPS.night.95@polygons[[1]], "area")/1000000,
                                   slot(area.pre.ARGOS.50@polygons[[1]], "area")/1000000,
                                   slot(area.pre.ARGOS.day.50@polygons[[1]], "area")/1000000,
                                   slot(area.pre.ARGOS.night.50@polygons[[1]], "area")/1000000,
                                   slot(area.post.ARGOS.50@polygons[[1]], "area")/1000000,
                                   slot(area.post.ARGOS.day.50@polygons[[1]], "area")/1000000,
                                   slot(area.post.ARGOS.night.50@polygons[[1]], "area")/1000000,
                                   slot(area.pre.ARGOS.95@polygons[[1]], "area")/1000000,
                                   slot(area.pre.ARGOS.day.95@polygons[[1]], "area")/1000000,
                                   slot(area.pre.ARGOS.night.95@polygons[[1]], "area")/1000000,
                                   slot(area.post.ARGOS.95@polygons[[1]], "area")/1000000,
                                   slot(area.post.ARGOS.day.95@polygons[[1]], "area")/1000000,
                                   slot(area.post.ARGOS.night.95@polygons[[1]], "area")/1000000))

write.csv(UD.df,
          file = paste0("data/UD_allIDs_", Sys.Date(), ".csv"), 
          quote = FALSE,
          row.names = FALSE)

```


Next individual-specific analyses. 
Extract UDs for each individual. Starting with pre with GPS data:
```{r message=FALSE}

if (!file.exists("RData/pre_GPS_UD_byID.rds")){
  pre.GPS.UD.byID <- UD.eachID(pre.GPS.kd, grid.value = grid.value)
  saveRDS(pre.GPS.UD.byID, file = "RData/pre_GPS_UD_byID.rds")  
} else {
  pre.GPS.UD.byID <- readRDS("RData/pre_GPS_UD_byID.rds")
}

if (!file.exists("RData/pre_GPS_UD_day_byID.rds")){
  pre.GPS.UD.day.byID <- UD.eachID(pre.GPS.kd.day, grid.value = grid.value)
  saveRDS(pre.GPS.UD.day.byID, file = "RData/pre_GPS_UD_day_byID.rds")  
} else {
  pre.GPS.UD.day.byID <- readRDS("RData/pre_GPS_UD_day_byID.rds")
}

if (!file.exists("RData/pre_GPS_UD_night_byID.rds")){
  pre.GPS.UD.night.byID <- UD.eachID(pre.GPS.kd.night, grid.value = grid.value)
  saveRDS(pre.GPS.UD.night.byID, file = "RData/pre_GPS_UD_night_byID.rds")  
} else {
  pre.GPS.UD.night.byID <- readRDS("RData/pre_GPS_UD_night_byID.rds")
}


```

And ARGOS data:

```{r message=FALSE}

if (!file.exists("RData/pre_ARGOS_UD_byID.rds")){
  pre.ARGOS.UD.byID <- UD.eachID(pre.ARGOS.kd, grid.value = grid.value)
  saveRDS(pre.ARGOS.UD.byID, file = "RData/pre_ARGOS_UD_byID.rds")  
} else {
  pre.ARGOS.UD.byID <- readRDS("RData/pre_ARGOS_UD_byID.rds")
}

if (!file.exists("RData/pre_ARGOS_UD_day_byID.rds")){
  pre.ARGOS.UD.day.byID <- UD.eachID(pre.ARGOS.kd.day, grid.value = grid.value)
  saveRDS(pre.ARGOS.UD.day.byID, file = "RData/pre_ARGOS_UD_day_byID.rds")  
} else {
  pre.ARGOS.UD.day.byID <- readRDS("RData/pre_ARGOS_UD_day_byID.rds")
}

if (!file.exists("RData/pre_ARGOS_UD_night_byID.rds")){
  pre.ARGOS.UD.night.byID <- UD.eachID(pre.ARGOS.kd.night, grid.value = grid.value)
  saveRDS(pre.ARGOS.UD.night.byID, file = "RData/pre_ARGOS_UD_night_byID.rds")  
} else {
  pre.ARGOS.UD.night.byID <- readRDS("RData/pre_ARGOS_UD_night_byID.rds")
}


```


Now for post:
```{r message=FALSE}

if (!file.exists("RData/post_GPS_UD_byID.rds")){
  post.GPS.UD.byID <- UD.eachID(post.GPS.kd, grid.value = grid.value)
  saveRDS(post.GPS.UD.byID, file = "RData/post_GPS_UD_byID.rds")  
} else {
  post.GPS.UD.byID <- readRDS("RData/post_GPS_UD_byID.rds")
}

if (!file.exists("RData/post_GPS_UD_day_byID.rds")){
  post.GPS.UD.day.byID <- UD.eachID(post.GPS.kd.day, grid.value = grid.value)
  saveRDS(post.GPS.UD.day.byID, file = "RData/post_GPS_UD_day_byID.rds")  
} else {
  post.GPS.UD.day.byID <- readRDS("RData/post_GPS_UD_day_byID.rds")
}

if (!file.exists("RData/post_GPS_UD_night_byID.rds")){
  post.GPS.UD.night.byID <- UD.eachID(post.GPS.kd.night, grid.value = grid.value)
  saveRDS(post.GPS.UD.night.byID, file = "RData/post_GPS_UD_night_byID.rds")  
} else {
  post.GPS.UD.night.byID <- readRDS("RData/post_GPS_UD_night_byID.rds")
}


```

and with ARGOS data
```{r message=FALSE}

if (!file.exists("RData/post_ARGOS_UD_byID.rds")){
  post.ARGOS.UD.byID <- UD.eachID(post.ARGOS.kd, grid.value = grid.value)
  saveRDS(post.ARGOS.UD.byID, file = "RData/post_ARGOS_UD_byID.rds")  
} else {
  post.ARGOS.UD.byID <- readRDS("RData/post_ARGOS_UD_byID.rds")
}

if (!file.exists("RData/post_ARGOS_UD_day_byID.rds")){
  post.ARGOS.UD.day.byID <- UD.eachID(post.ARGOS.kd.day, grid.value = grid.value)
  saveRDS(post.ARGOS.UD.day.byID, file = "RData/post_ARGOS_UD_day_byID.rds")  
} else {
  post.ARGOS.UD.day.byID <- readRDS("RData/post_ARGOS_UD_day_byID.rds")
}

if (!file.exists("RData/post_ARGOS_UD_night_byID.rds")){
  post.ARGOS.UD.night.byID <- UD.eachID(post.ARGOS.kd.night, grid.value = grid.value)
  saveRDS(post.ARGOS.UD.night.byID, file = "RData/post_ARGOS_UD_night_byID.rds")  
} else {
  post.ARGOS.UD.night.byID <- readRDS("RData/post_ARGOS_UD_night_byID.rds")
}


```


Bring in the body size information. This was done in deployment_table_Nov2019.R script and manually modified for missing data - some measurements were not collected when the tags were deployed so data from the closest captures were used.  Data were entered manually for three turtles in the Excel file: 52675 (all measurements) from 2007-01-23, 44366 (SCL and CCL) from 2009-02-26, and 126065 (Mass) from 2011-03-08).   Also, sat tag IDs were modified. 
126069 -> 12606905 5/13/2014
126071 -> 12607106 6/26/2014
126069 -> 12606907 7/24/2014
126071 -> 12607107 7/24/2014
21136/13183 -> 13183 This seems incorrect but it will be filtered out for now.

NAs in sex column were replaced with Us. 
```{r}
col.def <- cols(Turtle_ID = col_integer(),
                Year_caught = col_integer(),
                Month_caught = col_integer(),
                Day_caught = col_integer(),
                Sex = col_factor(levels = c("F", "M", "U")),
                Weight_kg = col_integer(),
                Str_Carapace_Length_cm = col_double(),
                Str_Carapace_Width_cm = col_double(),
                Cur_Carapace_Length_cm = col_double(),
                Cur_Carapace_Width_cm = col_double(),
                Sat_Tag_ID = col_integer())

# filter turtle_SDB for recent captures only. 
turtle.SDB <- readr::read_csv("data/turtle_SDB_corrected.csv",
                              col_types = col.def) %>%
  mutate(ArgosID = Sat_Tag_ID)  %>%
  mutate(Capture_Date = as.Date(paste0(Year_caught, '-',
                                       Month_caught, '-',
                                       Day_caught),
                                format = '%Y-%m-%d')) %>% 
  filter(Capture_Date > as.Date("2007-01-01")) -> turtle.SDB
```

Then combine it with pre data.  Get GPS summary;

```{r}
file.date <- "2019-11-01"
col.def <- cols(ArgosID = col_integer(),
                Date1 = col_datetime(format = "%Y-%m-%d %H:%M:%S"),
                n.days = col_double(),
                n.relocations.all = col_integer(),
                n.day.all = col_integer(),
                n.night.all = col_integer())

readr::read_csv(paste0("data/pre_sample_GPS_summary.csv"),
                col_types = col.def)  %>% 
  mutate(date = as.Date(Date1, 
                        format = "%Y-%m-%d")) %>% 
  transmute(ArgosID = ArgosID,
            n.days.GPS = n.days,
            n.relocations.all.GPS = n.relocations.all,
            n.day.all.GPS = n.day.all,
            n.night.all.GPS = n.night.all,
            date.GPS = date) -> dat.table.pre.GPS

# try to merge turtle.SDB and dat.table.pre.GPS:
dat.list <- list()
k <- 1
for (k in 1:nrow(dat.table.pre.GPS)){
  tmp.turtle.SDB <- filter(turtle.SDB, 
                           ArgosID == dat.table.pre.GPS$ArgosID[k])
  if (nrow(tmp.turtle.SDB) == 1){
    tmp.turtle.SDB %>% transmute(ArgosID = dat.table.pre.GPS$ArgosID[k],
                                 Turtle_ID = Turtle_ID,
                                 Capture_Date = as.Date(Capture_Date,
                                                        format = "%Y-%m-%d"),
                                 Sex = Sex,
                                 Mass_kg = Weight_kg,
                                 SCL_cm = Str_Carapace_Length_cm,
                                 SCW_cm = Str_Carapace_Width_cm,
                                 CCL_cm = Cur_Carapace_Length_cm,
                                 CCW_cm = Cur_Carapace_Width_cm) -> dat.list[[k]]
  } else {
    tmp.turtle.SDB %>% filter(Year_caught == year(dat.table.pre.GPS$date.GPS[k])) -> tmp.turtle.SDB
    if (nrow(tmp.turtle.SDB == 1)){
      tmp.turtle.SDB %>% transmute(ArgosID = dat.table.pre.GPS$ArgosID[k],
                                   Turtle_ID = Turtle_ID,
                                   Capture_Date = as.Date(Capture_Date,
                                                          format = "%Y-%m-%d"),
                                   Sex = Sex,
                                   Mass_kg = Weight_kg,
                                   SCL_cm = Str_Carapace_Length_cm,
                                   SCW_cm = Str_Carapace_Width_cm,
                                   CCL_cm = Cur_Carapace_Length_cm,
                                   CCW_cm = Cur_Carapace_Width_cm) -> dat.list[[k]]
    }
  }
}

dat.pre.GPS.morph <- do.call("rbind", dat.list)

dat.table.pre <- full_join(dat.table.pre.GPS, dat.pre.GPS.morph, by = "ArgosID")
# 
# if (!file.exists("data/pre_sample_summary_size.csv"))
#   write.csv(dat.table.pre,
#             "data/pre_sample_summary_size.csv",
#             quote = F,
#             row.names = F)
```

Get ARGOS data summary:

```{r}
col.def <- cols(ArgosID = col_integer(),
                Date1 = col_datetime(format = "%Y-%m-%d %H:%M:%S"),
                n.days = col_double(),
                n.relocations.all = col_integer(),
                total.DIAG = col_integer(),
                total.DS = col_integer(),
                LC1 = col_integer(),
                LC2 = col_integer(),
                LC3 = col_integer(),
                n.day.all = col_integer(),
                n.night.all = col_integer())

readr::read_csv(paste0("data/pre_sample_ARGOS_summary.csv"),
                col_types = col.def)  %>% 
  transmute(ArgosID = ArgosID,
            n.days.ARGOS = n.days,
            n.relocations.all.ARGOS = n.relocations.all,
            total.DIAG = total.DIAG,
            total.DS = total.DS,
            LC1 = LC1,
            LC2 = LC2, 
            LC3 = LC3,
            n.day.all.ARGOS = n.day.all,
            n.night.all.ARGOS = n.night.all,
            date.ARGOS = as.Date(Date1, 
                                 format = "%Y-%m-%d")) -> dat.table.pre.ARGOS

dat.table.pre %>% full_join(dat.table.pre.ARGOS, by = "ArgosID") %>%
  mutate(period = "pre") -> dat.table.pre

if (!file.exists("data/pre_sample_summary_size.csv"))
write.csv(dat.table.pre,
          "data/pre_sample_summary_size.csv",
          quote = F,
          row.names = F)
```


Do the same for the post period. 
```{r}

col.def <- cols(ArgosID = col_integer(),
                Date1 = col_datetime(format = "%Y-%m-%d %H:%M:%S"),
                n.days = col_double(),
                n.relocations.all = col_integer(),
                n.day.all = col_integer(),
                n.night.all = col_integer())

readr::read_csv(paste0("data/post_sample_GPS_summary.csv"),
                col_types = col.def)  %>% 
  transmute(ArgosID = ArgosID,
            n.days.GPS = n.days,
            n.relocations.all.GPS = n.relocations.all,
            n.day.all.GPS = n.day.all,
            n.night.all.GPS = n.night.all,
            date.GPS = as.Date(Date1, 
                        format = "%Y-%m-%d"))  -> dat.table.post.GPS

# try to merge turtle.SDB and dat.table.post:
dat.list <- list()
k <- 1
for (k in 1:nrow(dat.table.post.GPS)){
  tmp.turtle.SDB <- filter(turtle.SDB, 
                           ArgosID == dat.table.post.GPS$ArgosID[k])
  
  if (nrow(tmp.turtle.SDB) == 1){
    tmp.turtle.SDB %>% transmute(ArgosID = dat.table.post.GPS$ArgosID[k],
                                 Turtle_ID = Turtle_ID,
                                 Capture_Date = as.Date(Capture_Date,
                                                        format = "%Y-%m-%d"),
                                 Sex = Sex,
                                 Mass_kg = Weight_kg,
                                 SCL_cm = Str_Carapace_Length_cm,
                                 SCW_cm = Str_Carapace_Width_cm,
                                 CCL_cm = Cur_Carapace_Length_cm,
                                 CCW_cm = Cur_Carapace_Width_cm) -> dat.list[[k]]
  } else {
    tmp.turtle.SDB %>% filter(Year_caught == year(dat.table.post.GPS$date.GPS[k])) -> tmp.turtle.SDB
    if (nrow(tmp.turtle.SDB == 1)){
      tmp.turtle.SDB %>% transmute(ArgosID = dat.table.post.GPS$ArgosID[k],
                                   Turtle_ID = Turtle_ID,
                                   Capture_Date = as.Date(Capture_Date,
                                                          format = "%Y-%m-%d"),
                                   Sex = Sex,
                                   Mass_kg = Weight_kg,
                                   SCL_cm = Str_Carapace_Length_cm,
                                   SCW_cm = Str_Carapace_Width_cm,
                                   CCL_cm = Cur_Carapace_Length_cm,
                                   CCW_cm = Cur_Carapace_Width_cm) -> dat.list[[k]]
    }
  }
}

dat.post.GPS.morph <- do.call("rbind", dat.list)

dat.table.post <- full_join(dat.table.post.GPS, dat.post.GPS.morph, by = "ArgosID")

# if (!file.exists("data/post_sample_summary_size.csv"))
#   write.csv(dat.table.post,
#             "data/post_sample_summary_size.csv",
#             quote = F,
#             row.names = F)
```

Also for ARGOS data

```{r}
col.def <- cols(ArgosID = col_integer(),
                Date1 = col_datetime(format = "%Y-%m-%d %H:%M:%S"),
                n.days = col_double(),
                n.relocations.all = col_integer(),
                total.DIAG = col_integer(),
                total.DS = col_integer(),
                LC1 = col_integer(),
                LC2 = col_integer(),
                LC3 = col_integer(),
                n.day.all = col_integer(),
                n.night.all = col_integer())

readr::read_csv(paste0("data/post_sample_ARGOS_summary.csv"),
                col_types = col.def)  %>% 
  transmute(ArgosID = ArgosID,
            n.days.ARGOS = n.days,
            n.relocations.all.ARGOS = n.relocations.all,
            total.DIAG = total.DIAG,
            total.DS = total.DS,
            LC1 = LC1,
            LC2 = LC2, 
            LC3 = LC3,
            n.day.all.ARGOS = n.day.all,
            n.night.all.ARGOS = n.night.all,
            date.ARGOS = as.Date(Date1, 
                                 format = "%Y-%m-%d")) -> dat.table.post.ARGOS

dat.table.post %>% full_join(dat.table.post.ARGOS, by = "ArgosID") %>%
  mutate(period = "post") -> dat.table.post

#if (!file.exists("data/post_sample_summary_size.csv"))
  write.csv(dat.table.post,
            "data/post_sample_summary_size.csv",
            quote = F,
            row.names = F)
```

Then combine them teogther

```{r}
dat.table <- rbind(dat.table.pre, dat.table.post) 

GPS.areas.df <- rbind(pre.GPS.UD.byID$area, 
                      post.GPS.UD.byID$area) %>%
  transmute(ArgosID = ID,
            area.50.all.GPS = area.50,
            area.75.all.GPS = area.75,
            area.95.all.GPS = area.95)

GPS.areas.night.df <- rbind(pre.GPS.UD.night.byID$area, 
                            post.GPS.UD.night.byID$area)%>%
  transmute(ArgosID = ID,
            area.50.night.GPS = area.50,
            area.75.night.GPS = area.75,
            area.95.night.GPS = area.95)

GPS.areas.day.df <- rbind(pre.GPS.UD.day.byID$area, 
                          post.GPS.UD.day.byID$area)%>%
  transmute(ArgosID = ID,
            area.50.day.GPS = area.50,
            area.75.day.GPS = area.75,
            area.95.day.GPS = area.95)

ARGOS.areas.df <- rbind(pre.ARGOS.UD.byID$area, 
                        post.ARGOS.UD.byID$area) %>%
  transmute(ArgosID = ID,
            area.50.all.ARGOS = area.50,
            area.75.all.ARGOS = area.75,
            area.95.all.ARGOS = area.95)

ARGOS.areas.night.df <- rbind(pre.ARGOS.UD.night.byID$area, 
                              post.ARGOS.UD.night.byID$area)%>%
  transmute(ArgosID = ID,
            area.50.night.ARGOS = area.50,
            area.75.night.ARGOS = area.75,
            area.95.night.ARGOS = area.95)

ARGOS.areas.day.df <- rbind(pre.ARGOS.UD.day.byID$area, 
                            post.ARGOS.UD.day.byID$area)%>%
  transmute(ArgosID = ID,
            area.50.day.ARGOS = area.50,
            area.75.day.ARGOS = area.75,
            area.95.day.ARGOS = area.95)

dat.table <- left_join(dat.table, GPS.areas.df, by = "ArgosID") %>%
  left_join(GPS.areas.night.df, by = "ArgosID") %>%
  left_join(GPS.areas.day.df, by = "ArgosID") %>% 
  left_join(ARGOS.areas.df, by = "ArgosID") %>%
  left_join(ARGOS.areas.night.df, by = "ArgosID") %>%
  left_join(ARGOS.areas.day.df, by = "ArgosID")

write.csv(dat.table, file = "data/IDvsUDs.csv", 
          quote = F, row.names = F)

# ggplot(data = dat.table) +
#   geom_point(aes(x = area.95.all.GPS,
#                  y = area.95.all.ARGOS,
#                  color = period))
```


Compare with other files created at different time:

```{r}
pre.GPS.day.byID <- readRDS("RData/pre_GPS_UD_day_byID.rds")
pre.GPS.day.byID$area$period <- "pre"
pre.GPS.day.byID$area$day1night2 <- 1
pre.GPS.night.byID <- readRDS("RData/pre_GPS_UD_night_byID.rds")
pre.GPS.night.byID$area$period <- "pre"
pre.GPS.night.byID$area$day1night2 <- 2
post.GPS.day.byID <- readRDS("RData/post_GPS_UD_day_byID.rds")
post.GPS.day.byID$area$period <- "post"
post.GPS.day.byID$area$day1night2 <- 1

post.GPS.night.byID <- readRDS("RData/post_GPS_UD_night_byID.rds")
post.GPS.night.byID$area$period <- "post"
post.GPS.night.byID$area$day1night2 <- 2

test.data <- rbind(pre.GPS.day.byID$area,
                   pre.GPS.night.byID$area,
                   post.GPS.day.byID$area,
                   post.GPS.night.byID$area)



```


Plotting starts here:
Make a plot for pre using all data:
```{r}

pre.ver.50.df <- broom::tidy(spTransform(area.pre.GPS.50, CRS("+proj=longlat")))
pre.ver.95.df <- broom::tidy(spTransform(area.pre.GPS.95, CRS("+proj=longlat")))

map.pre.HR <- map.sdbay.south + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2008.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_polygon(data = pre.ver.95.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "cornsilk",
               alpha = 0.6) + 
  geom_polygon(data = pre.ver.50.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "red3",
               alpha = 0.6) + 
  # geom_point(data = pre.all,
  #            aes(x = Lon1, y = Lat1),
  #            alpha = 0.5,
  #            size = 0.2)+ 
  # geom_polygon(data = water.df,
  #              aes(x = long,
  #                  y = lat,
  #                  group = group),
  #              fill = "blue",
  #              alpha = 0.2) +

  #coord_map() + 
  #labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/UD_GPS_pre.png", 
         plot = map.pre.HR,
         device = "png",
         dpi = 600)

plot(map.pre.HR)
```

Make a plot for pre day:
```{r}

pre.day.ver.50.df <- broom::tidy(spTransform(area.pre.GPS.day.50, CRS("+proj=longlat")))
pre.day.ver.95.df <- broom::tidy(spTransform(area.pre.GPS.day.95, CRS("+proj=longlat")))

map.pre.day.HR <- map.sdbay.south + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2008.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_polygon(data = pre.day.ver.95.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "cornsilk",
               alpha = 0.6) + 
  geom_polygon(data = pre.day.ver.50.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "red3",
               alpha = 0.6) + 
  # geom_point(data = pre.all,
  #            aes(x = Lon1, y = Lat1),
  #            alpha = 0.5,
  #            size = 0.2)+ 
  # geom_polygon(data = water.df,
  #              aes(x = long,
  #                  y = lat,
  #                  group = group),
  #              fill = "blue",
  #              alpha = 0.2) +

  #coord_map() + 
  #labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/UD_GPS_pre_day.png", 
         plot = map.pre.day.HR,
         device = "png",
         dpi = 600)

plot(map.pre.day.HR)
```

Make a plot for pre night:
```{r}

pre.night.ver.50.df <- broom::tidy(spTransform(area.pre.GPS.night.50, 
                                               CRS("+proj=longlat")))

pre.night.ver.95.df <- broom::tidy(spTransform(area.pre.GPS.night.95, 
                                               CRS("+proj=longlat")))

map.pre.night.HR <- map.sdbay.south + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2008.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_polygon(data = pre.night.ver.95.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "cornsilk",
               alpha = 0.6) + 
  geom_polygon(data = pre.night.ver.50.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "red3",
               alpha = 0.6) + 
  # geom_point(data = pre.all,
  #            aes(x = Lon1, y = Lat1),
  #            alpha = 0.5,
  #            size = 0.2)+ 
  # geom_polygon(data = water.df,
  #              aes(x = long,
  #                  y = lat,
  #                  group = group),
  #              fill = "blue",
  #              alpha = 0.2) +

  #coord_map() + 
  #labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/UD_GPS_pre_night.png", 
         plot = map.pre.night.HR,
         device = "png",
         dpi = 600)

plot(map.pre.night.HR)
```

Make a plot for post using all data:
```{r}

post.ver.50.df <- broom::tidy(spTransform(area.post.GPS.50, CRS("+proj=longlat")))
post.ver.95.df <- broom::tidy(spTransform(area.post.GPS.95, CRS("+proj=longlat")))

map.post.HR <- map.sdbay.south + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2014.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_polygon(data = post.ver.95.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "cornsilk",
               alpha = 0.6) + 
  geom_polygon(data = post.ver.50.df,
               aes(x = long, y = lat, 
                   group = group),
               fill = "red3",
               alpha = 0.6) + 
  # geom_point(data = post.all,
  #            aes(x = Lon1, y = Lat1),
  #            alpha = 0.5,
  #            size = 0.2)+ 
  # # geom_polygon(data = water.df,
  #              aes(x = long,
  #                  y = lat,
  #                  group = group),
  #              fill = "blue",
  #              alpha = 0.2) +

  #coord_map() + 
  #labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/UD_GPS_post.png", 
         plot = map.post.HR,
         device = "png",
         dpi = 600)

plot(map.post.HR)
```

Make a plot for post day:
```{r}

post.day.ver.50.df <- broom::tidy(spTransform(area.post.GPS.day.50, CRS("+proj=longlat")))
post.day.ver.95.df <- broom::tidy(spTransform(area.post.GPS.day.95, CRS("+proj=longlat")))

map.post.day.HR <- map.sdbay.south + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2014.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_polygon(data = post.day.ver.95.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "cornsilk",
               alpha = 0.6) + 
  geom_polygon(data = post.day.ver.50.df,
               aes(x = long, y = lat, 
                   group = group),
               fill = "red3",
               alpha = 0.6) + 
  # geom_point(data = post.all,
  #            aes(x = Lon1, y = Lat1),
  #            alpha = 0.5,
  #            size = 0.2)+ 
  # # geom_polygon(data = water.df,
  #              aes(x = long,
  #                  y = lat,
  #                  group = group),
  #              fill = "blue",
  #              alpha = 0.2) +

  #coord_map() + 
  #labs(color = 'ARGOS ID') + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/UD_GPS_post_day.png", 
         plot = map.post.day.HR,
         device = "png",
         dpi = 600)

plot(map.post.day.HR)
```


Make a plot for post night:
```{r}

post.night.ver.50.df <- broom::tidy(spTransform(area.post.GPS.night.50,
                                                CRS("+proj=longlat")))
post.night.ver.95.df <- broom::tidy(spTransform(area.post.GPS.night.95,
                                                CRS("+proj=longlat")))

map.post.night.HR <- map.sdbay.south + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat)) +
               #fill = "blue",alpha = 0.6) + 
  geom_polygon(data = SDBay.eelg.2014.df,
               aes(x = long,
                   y = lat,
                   group = group),
               fill = "green",
               alpha = 0.5) +
  geom_polygon(data = post.night.ver.95.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "cornsilk",
               alpha = 0.6) + 
  geom_polygon(data = post.night.ver.50.df,
               aes(x = long, y = lat, 
                   group = group),
               fill = "red3",
               alpha = 0.6) + 
  xlab('Longitude') + ylab('Latitude') + 
  theme(#legend.title = element_text(size = 10, hjust = 0.5),
        #legend.text = element_text(size = 8, vjust = 0),
        legend.position = "none")

if (save.figure)
  ggsave(filename = "figures/UD_GPS_post_night.png", 
         plot = map.post.night.HR,
         device = "png",
         dpi = 600)

plot(map.post.night.HR)
```



UDs for individual turtles:
```{r}

p.h.pre.eachID <- ggplot() + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat, group = group),
               fill = water.color,
               color = "black",
               alpha = 0.4) +
  geom_polygon(data = pre.GPS.UD.byID$vert.95.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "aquamarine4",
               alpha = 0.6) + 
  geom_polygon(data = pre.GPS.UD.byID$vert.50.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "red3",
               alpha = 0.6) +
  coord_map() + 
  facet_grid(. ~ ID) +
  facet_wrap( ~ ID, nrow = 2) + 
  labs(x = "", y = "")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  scale_x_continuous(breaks = c(-117.14, -117.12, -117.10),
                     limits = c(-117.15, -117.09)) +
  scale_y_continuous(breaks = c(32.60, 32.62, 32.64),
                     limits = c(32.59, 32.65))

if (save.figure)
  ggsave(filename = "figures/UD_GPS_pre_byID.png", 
         plot = map.pre.night.HR,
         device = "png",
         dpi = 600)

plot(p.h.pre.eachID)
```

```{r}

p.h.post.eachID <- ggplot() + 
  geom_polygon(data = SDBay.df,
               aes(x = long, y = lat, group = group),
               fill = water.color,
               color = "black",
               alpha = 0.4) +
  geom_polygon(data = post.GPS.UD.byID$vert.95.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "aquamarine4",
               alpha = 0.6) + 
  geom_polygon(data = post.GPS.UD.byID$vert.50.df,
               aes(x = long, y = lat,
                   group = group),
               fill = "red3",
               alpha = 0.6) + 
  coord_map() + facet_grid(. ~ ID) +
  facet_wrap( ~ ID, nrow = 3) + 
  labs(x = "", y = "")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
   scale_x_continuous(breaks = c(-117.14, -117.12, -117.10),
                     limits = c(-117.15, -117.09)) +
  scale_y_continuous(breaks = c(32.60, 32.62, 32.64),
                     limits = c(32.59, 32.65))

plot(p.h.post.eachID)
```



Save figures:
```{r}
if (save.figure){
  # ggsave(filename = paste0("figures/HR_pre_h_comp_GPS_", Sys.Date(), ".png"),
  #      plot = h.adhoc.pre$figure,
  #      dpi = 600,
  #      device = "png")
  # ggsave(filename = paste0("figures/HR_post_h_comp_GPS_", Sys.Date(), ".png"),
  #        plot = h.adhoc.post$figure,
  #        dpi = 600,
  #        device = "png")
  # ggsave(filename = paste0("figures/HR_pre_day_h_comp_GPS_", Sys.Date(), ".png"),
  #        plot = h.adhoc.pre.day$figure,
  #        dpi = 600,
  #        device = "png")
  # ggsave(filename = paste0("figures/HR_pre_night_h_comp_GPS_", Sys.Date(), ".png"),
  #        plot = h.adhoc.pre.night$figure,
  #        dpi = 600,
  #        device = "png")
  # ggsave(filename = paste0("figures/HR_post_day_h_comp_GPS_", Sys.Date(), ".png"),
  #        plot = h.adhoc.post.day$figure,
  #        dpi = 600,
  #        device = "png")
  # ggsave(filename = paste0("figures/HR_post_night_h_comp_GPS_", Sys.Date(), ".png"),
  #        plot = h.adhoc.post.night$figure,
  #        dpi = 600,
  #        device = "png")
  ggsave(filename = paste0("figures/HR_pre_h_", h.pre, "_GPS_", Sys.Date(), ".png"),
         plot = map.pre.HR,
         dpi = 600,
         device = "png")
  
  ggsave(filename = paste0("figures/HR_post_h_", h.post, "_GPS_", Sys.Date(), ".png"),
         plot = map.post.HR,
         dpi = 600,
         device = "png")
  
  ggsave(filename = paste0("figures/HR_pre_day_h_", 
                           h.pre.day, "_GPS_", Sys.Date(), ".png"),
         plot = map.pre.day.HR,
         dpi = 600,
         device = "png")
  
  ggsave(filename = paste0("figures/HR_post_day_h_", 
                           h.post.day, "_GPS_", Sys.Date(), ".png"),
         plot = map.post.day.HR,
         dpi = 600,
         device = "png")
  
  ggsave(filename = paste0("figures/HR_pre_night_h_", 
                           h.pre.night, "_GPS_", Sys.Date(), ".png"),
         plot = map.pre.night.HR,
         dpi = 600,
         device = "png")
  
  ggsave(filename = paste0("figures/HR_post_night_h_", 
                           h.post.night, "_GPS_", Sys.Date(), ".png"),
         plot = map.post.night.HR,
         dpi = 600,
         device = "png")
  
  ggsave(filename = paste0("figures/HR50_difference_GPS_", 
                           Sys.Date(), ".png"),
         plot = hist.dif.50,
         dpi = 600,
         device = "png")
  
  ggsave(filename = paste0("figures/HRbyID_pre_GPS_",
                           Sys.Date(), ".png"),
         plot = p.h.pre.eachID,
         dpi = 600,
         device = "png")
  ggsave(filename = paste0("figures/HRbyID_post_GPS_",
                           Sys.Date(), ".png"),
         plot = p.h.post.eachID,
         dpi = 600,
         device = "png")
}

# too big to save in a file - can be done but unnecessary.
# save(list = ls(),
#      file = paste0("RData/output_HR_analysis_GPS_LC_", Sys.Date(), ".RData"))
#plot(map.post.HR)
```



